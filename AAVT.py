# ä½œè€…ï¼šchenyme
# ç‰ˆæœ¬ï¼šv0.4
# åšå®¢ç«™ï¼šå¾…æ›´æ–°

import os
import toml
import torch
import shutil
import datetime
import streamlit as st
from utils.utils import (aavt_chatbot, get_whisper_result, kimi_translate, openai_translate1, openai_translate2,
                         generate_srt_from_result, srt_mv, srt_to_vtt, srt_to_ass, srt_to_stl, show_video,
                         parse_srt_file, convert_size, cache)

project_dir = os.path.dirname(os.path.abspath(__file__)).replace("\\", "/")
log_dir = project_dir + "/public/log.md"  # æ›´æ–°æ—¥å¿—
read_dir = project_dir + "/public/README.md"  # é¡¹ç›®æ–‡æ¡£
config_dir = project_dir + "/config/"  # é…ç½®æ–‡ä»¶
cache_dir = project_dir + "/cache/"  # æœ¬åœ°ç¼“å­˜

with open('public/README.md', 'r', encoding='utf-8') as file:
    markdown_content = file.read()
config = toml.load("config/config.toml")  # åŠ è½½é…ç½®
st.session_state.openai_key = config["GPT"]["openai_key"]
st.session_state.openai_base = config["GPT"]["openai_base"]

st.set_page_config(
    page_title="AAVT v0.4",
    page_icon="ğŸï¸",
    layout="wide",  # è®¾ç½®å¸ƒå±€æ ·å¼ä¸ºå®½å±•ç¤º
    initial_sidebar_state="expanded"  # è®¾ç½®åˆå§‹è¾¹æ çŠ¶æ€ä¸ºå±•å¼€
)
st.title("AIå…¨è‡ªåŠ¨è§†é¢‘ç¿»è¯‘ğŸï¸")

tab1, tab2, tab3 = st.tabs(["ä¸»é¡µ", "è®¾ç½®", "å…³äº"])

with st.sidebar:  # ä¾§è¾¹æ åŠŸèƒ½
    st.title("POWERED BY @CHENYME")
    st.caption("ğŸ–¥Chenyme-AAVT Versionï¼š0.4")
    st.write(
        "æ­å–œä½ æˆåŠŸå¯åŠ¨äº†AAVTé¡¹ç›®ï¼è¯·å…ˆå‰å¾€è®¾ç½®é¡µé¢é…ç½®ç¯å¢ƒï¼ŒåŒæ—¶ç¡®ä¿æŒ‰ç…§æ­¥éª¤å®‰è£…å¥½æ‰€æœ‰ä¾èµ–ç¯å¢ƒå’Œåº“ï¼Œä»¥ä¿è¯é¡¹ç›®ç¨³å®šè¿è¡Œï¼")

    sidebar_chat = st.container(border=True, height=500)
    sidebar_chat.caption("ğŸš€ A ChatBot Based on OpenAI LLM")
    sidebar_chat_prompt = st.text_input("è¾“å…¥æ‚¨çš„é—®é¢˜",
                                        help="è¿™æ˜¯åŸºäº `gpt-3.5-turbo` çš„AIåŠ©æ‰‹ï¼Œä½ å¯ä»¥é—®ä»»ä½•é—®é¢˜ï¼ŒæŒ‰ `Enter` ä»¥å‘é€ï¼Œä¸ºäº†èŠ‚çœTokenï¼Œç›¸åŒçš„é—®é¢˜ä¼šè¢«ç¼“å­˜ï¼Œæ‚¨å¯ä»¥åœ¨å³ä¸Šè§’è®¾ç½®ä¸­ç‚¹å‡» `Clear Cahce` æ¸…æ¥šç¼“å­˜å¹¶é‡æ–°æé—®ã€‚")

    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "assistant", "content": "æ¬¢è¿æ¥åˆ°AAVT v0.4ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œæ‚¨å¯ä»¥éšæ—¶å‘æˆ‘å‘èµ·æé—®ï¼"}]
    for msg in st.session_state.messages:
        sidebar_chat.chat_message(msg["role"]).write(msg["content"])

    if sidebar_chat_prompt != '':
        msg = aavt_chatbot(markdown_content, sidebar_chat_prompt, st.session_state.openai_key,
                           st.session_state.openai_base)
        sidebar_chat.chat_message("user").write(sidebar_chat_prompt)
        sidebar_chat.chat_message("assistant").write(msg)

with tab1:  # ä¸»ç•Œé¢åŠŸèƒ½

    col1, col2 = st.columns(2, gap="medium")
    with col1:
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader("è¯·åœ¨è¿™é‡Œä¸Šä¼ è§†é¢‘ï¼š", type=['mp4', 'mov'])
        if uploaded_file is not None:
            st.success("ä¸Šä¼ æˆåŠŸ")

        # GPUåŠ é€Ÿ
        wdc = not torch.cuda.is_available()
        GPU_on = st.toggle('å¯ç”¨GPUåŠ é€Ÿ*', disabled=wdc, help='è¯·ç¡®ä¿æ‚¨æ­£ç¡®å®‰è£…äº†cudaã€pytorchï¼Œå¦åˆ™è¯¥é€‰é¡¹å¼€å¯æ— æ•ˆï¼')
        device = 'cuda' if GPU_on else 'cpu'

        # ç¿»è¯‘æ¨¡å‹
        translate_option = st.selectbox('è¯·åœ¨è¿™é‡Œé€‰æ‹©ç¿»è¯‘æ¨¡å‹ï¼š', ('kimi', 'gpt-3.5-turbo', 'gpt-4', 'æ— éœ€ç¿»è¯‘'),
                                        index=0)
        if translate_option != 'æ— éœ€ç¿»è¯‘':
            col3, col4 = st.columns(2)
            with col3:
                language1 = st.selectbox('åŸå§‹è¯­è¨€', ('ä¸­æ–‡', 'English', 'æ—¥æœ¬èª', 'í•œêµ­ì¸', 'Italiano', 'Deutsch'),
                                         index=1)
            with col4:
                language2 = st.selectbox('ç›®æ ‡è¯­è¨€', ('ä¸­æ–‡', 'English', 'æ—¥æœ¬èª', 'í•œêµ­ì¸', 'Italiano', 'Deutsch'),
                                         index=0)
            if st.button('è¿è¡Œç¨‹åº'):
                if uploaded_file is not None:
                    with st.spinner('æ­£åœ¨åŠ è½½è§†é¢‘ç¼“å­˜...'):
                        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H-%M-%S")
                        output_file = cache_dir + current_time
                        os.makedirs(output_file)
                        with open(output_file + "/uploaded.mp4", "wb") as file:
                            file.write(uploaded_file.getbuffer())

                    with st.spinner('æ­£åœ¨è¯†åˆ«è§†é¢‘å†…å®¹...'):
                        # whisperè¯†åˆ«
                        result = get_whisper_result(uploaded_file, output_file, device, st.session_state.w_model_option,
                                                    st.session_state.w_name)
                        print("whisperè¯†åˆ«ï¼š" + result['text'])

                    with st.spinner('æ­£åœ¨ç¿»è¯‘æ–‡æœ¬...'):
                        if translate_option == 'kimi':
                            result = kimi_translate(st.session_state.kimi_key, result, language1,
                                                    language2)  # ä½¿ç”¨kimiç¿»è¯‘æˆç›®æ ‡è¯­è¨€
                        elif translate_option == 'gpt-3.5-turbo':
                            result = openai_translate1(st.session_state.openai_key, st.session_state.openai_base, st.session_state.proxy_on,
                                                       result, language1, language2)  # ä½¿ç”¨gpt3.5ç¿»è¯‘æˆç›®æ ‡è¯­è¨€
                        elif translate_option == 'gpt-4':
                            result = openai_translate2(st.session_state.openai_key, st.session_state.openai_base, st.session_state.proxy_on,
                                                       result, language1, language2, )  # ä½¿ç”¨gpt4ç¿»è¯‘æˆç›®æ ‡è¯­è¨€

                    with st.spinner('æ­£åœ¨ç”ŸæˆSRTå­—å¹•æ–‡ä»¶...'):
                        srt_content = generate_srt_from_result(result)  # ç”ŸæˆSRTå­—å¹•å†…å®¹
                        with open(output_file + "/output.srt", 'w', encoding='utf-8') as srt_file:  # å°†SRTå†…å®¹å†™å…¥SRTæ–‡ä»¶
                            srt_file.write(srt_content)

                    with st.spinner('æ­£åœ¨åˆå¹¶è§†é¢‘ï¼Œè¯·è€å¿ƒç­‰å¾…è§†é¢‘ç”Ÿæˆ...'):
                        srt_mv(output_file)

                    st.session_state.srt_content = srt_content
                    st.session_state.output = output_file
                else:
                    st.warning("è¯·å…ˆä¸Šä¼ è§†é¢‘")

        elif translate_option == 'æ— éœ€ç¿»è¯‘':
            if st.button('è¿è¡Œç¨‹åº'):
                if uploaded_file is not None:
                    with st.spinner('æ­£åœ¨åŠ è½½è§†é¢‘ç¼“å­˜...'):
                        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H-%M-%S")
                        output_file = cache_dir + current_time
                        os.makedirs(output_file)
                        with open(output_file + "/uploaded.mp4", "wb") as file:
                            file.write(uploaded_file.getbuffer())

                    with st.spinner('æ­£åœ¨è¯†åˆ«è§†é¢‘å†…å®¹...'):
                        # whisperè¯†åˆ«
                        result = get_whisper_result(uploaded_file, cache_dir, device, st.session_state.w_model_option,
                                                    st.session_state.w_name)

                        print("whisperè¯†åˆ«ï¼š" + result['text'])

                    with st.spinner('æ­£åœ¨ç”ŸæˆSRTå­—å¹•æ–‡ä»¶...'):
                        srt_content = generate_srt_from_result(result)  # ç”ŸæˆSRTå­—å¹•å†…å®¹
                        with open(output_file + "/output.srt", 'w', encoding='utf-8') as srt_file:  # å°†SRTå†…å®¹å†™å…¥SRTæ–‡ä»¶
                            srt_file.write(srt_content)

                    with st.spinner('æ­£åœ¨åˆå¹¶è§†é¢‘ï¼Œè¯·è€å¿ƒç­‰å¾…è§†é¢‘ç”Ÿæˆ...'):
                        srt_mv(output_file)

                    st.session_state.srt_content = srt_content
                    st.session_state.output = output_file
                else:
                    st.warning("è¯·å…ˆä¸Šä¼ è§†é¢‘")

    with col2:
        c = st.container(border=True, height=500)
        c.write('é¢„è§ˆå’Œä¸‹è½½ï¼ˆPreview & Downloadï¼‰')
        captions_option = c.radio('ä¸‹è½½çš„å­—å¹•æ ¼å¼ï¼š', ('srt', 'vtt', 'ass', 'stl'), index=0, horizontal=True)
        try:
            if captions_option == 'srt':
                c.download_button(
                    label="ç‚¹å‡»ä¸‹è½½SRTå­—å¹•æ–‡ä»¶",
                    data=st.session_state.srt_content.encode('utf-8'),
                    key='srt_download',
                    file_name='output.srt',
                    mime='text/srt',
                )
            elif captions_option == 'vtt':
                vtt_content = srt_to_vtt(st.session_state.srt_content)
                c.download_button(
                    label="ç‚¹å‡»ä¸‹è½½VTTå­—å¹•æ–‡ä»¶",
                    data=vtt_content.encode('utf-8'),
                    key='vtt_download',
                    file_name='output.vvt',
                    mime='text/vtt',
                )
            elif captions_option == 'ass':
                ass_content = srt_to_ass(st.session_state.srt_content)
                c.download_button(
                    label="ç‚¹å‡»ä¸‹è½½ASSå­—å¹•æ–‡ä»¶",
                    data=ass_content.encode('utf-8'),
                    key='ass_download',
                    file_name='output.ass',
                    mime='text/ass',
                )
            elif captions_option == 'stl':
                stl_content = srt_to_stl(st.session_state.srt_content)
                c.download_button(
                    label="ç‚¹å‡»ä¸‹è½½STLå­—å¹•æ–‡ä»¶",
                    data=stl_content.encode('utf-8'),
                    key='stl_download',
                    file_name='output.stl',
                    mime='text/stl',
                )

        except:
            c.warning('è¿™é‡Œæ˜¯é¢„è§ˆçª—å£ï¼Œè¿è¡Œåè‡ªåŠ¨æ˜¾ç¤ºé¢„è§ˆç»“æœã€‚')

        try:
            video_bytes = show_video(st.session_state.output)
            c.video(video_bytes)
        except:
            c.write('')

    st.write('''
    ------
    ##### å®éªŒåŠŸèƒ½ğŸ§ª
    ''')
    st.caption("è¿è¡Œç¨‹åºåè‡ªåŠ¨æ˜¾ç¤ºï¼Œå®é™…å¯èƒ½ä¼šæœ‰BUGï¼Œåç»­ç‰ˆæœ¬ä¼šé€æ­¥å®Œå–„å¹¶å®è£…ï¼")
    try:
        srt_data = parse_srt_file(st.session_state.srt_content)
        edited_data = st.data_editor(srt_data, height=300, hide_index=True)

        if edited_data is not None:
            st.write('ç¼–è¾‘åçš„æ•°æ®ï¼š')
            st.dataframe(edited_data, height=300, hide_index=True)
    except:
        st.write('')

with tab2:
    openai_api_key = config["GPT"]["openai_key"]
    openai_api_base = config["GPT"]["openai_base"]
    kimi_api_key = config["KIMI"]["kimi_key"]
    whisper_version = config["WHISPER"]["whisper_version_default"]
    whisper_model = config["WHISPER"]["whisper_model_default"]

    # Whisperæ¨¡å‹
    st.write("#### Whisperè¯†åˆ«è®¾ç½®")
    w_version_d = {'openai-whisper': 0, 'faster-whisper': 1}
    w_model_d = {'tiny': 0, 'base': 1, 'small': 2, 'medium': 3, 'large': 4}
    w_version = st.selectbox('é€‰æ‹©whisperç‰ˆæœ¬', ('openai-whisper', 'faster-whisper'),
                             index=w_version_d[whisper_version])
    w_model_option = st.selectbox('é€‰æ‹©è¯†åˆ«æ¨¡å‹', ('tiny', 'base', 'small', 'medium', 'large'),
                                  index=w_model_d[whisper_model])

    if w_version != whisper_version:
        config["WHISPER"]["whisper_version_default"] = w_version
        with open(config_dir + '/config.toml', 'w') as file:
            toml.dump(config, file)
        st.success("é»˜è®¤ç‰ˆæœ¬å·²åˆ‡æ¢ä¸ºï¼š" + w_version)
    if w_model_option != whisper_model:
        config["WHISPER"]["whisper_model_default"] = w_model_option
        with open(config_dir + '/config.toml', 'w') as file:
            toml.dump(config, file)
        st.success("é»˜è®¤æ¨¡å‹å·²åˆ‡æ¢ä¸ºï¼š" + w_model_option)
    st.write('------')

    # OPENAIè´¦æˆ·
    st.write("#### ç¿»è¯‘è®¾ç½®")
    st.write("##### KIMIè´¦æˆ·è®¾ç½®")
    new_kimi_key = st.text_input("KIMI-API-KEYï¼š")
    st.write("##### OPENAIè´¦æˆ·è®¾ç½®")
    proxy_on = st.toggle('å¯ç”¨ä»£ç†', help='å¦‚æœä½ èƒ½ç›´æ¥è®¿é—®openai.comï¼Œåˆ™æ— éœ€å¯ç”¨ã€‚')
    new_openai_key = st.text_input("OPENAI-API-KEYï¼š")
    new_openai_base = st.text_input("OPENAI-API-BASEï¼š")

    if st.button("ä¿å­˜"):
        if new_kimi_key != kimi_api_key and new_kimi_key != "":
            config["KIMI"]["kimi_key"] = new_kimi_key
            kimi_api_key = new_kimi_key
        if new_openai_base != openai_api_base and new_openai_base != "":
            config["GPT"]["openai_base"] = new_openai_base
            openai_api_base = new_openai_base
        if new_openai_key != openai_api_key and new_openai_key != "":
            config["GPT"]["openai_key"] = new_openai_key
            openai_api_key = new_openai_key
        with open(config_dir + "config.toml", 'w') as file:
            toml.dump(config, file)
        st.success("å·²ä¿å­˜")
    st.write('------')

    # æœ¬åœ°ç¼“å­˜
    st.write("#### æœ¬åœ°ç¼“å­˜")
    st.write(f"æœ¬åœ°ç¼“å­˜å·²å ç”¨ï¼š{convert_size(cache(cache_dir))}")
    if st.button("æ¸…é™¤æœ¬åœ°ç¼“å­˜"):
        # è·å–æ–‡ä»¶å¤¹å†…æ‰€æœ‰æ–‡ä»¶çš„åˆ—è¡¨
        file_list = os.listdir(cache_dir)
        if not file_list:
            st.error("æ— æœ¬åœ°ç¼“å­˜æ–‡ä»¶ã€‚")
        else:
            # éå†åˆ—è¡¨ä¸­çš„æ–‡ä»¶ï¼Œå¹¶åˆ é™¤æ¯ä¸ªæ–‡ä»¶
            for file_name in file_list:
                file_path = os.path.join(cache_dir, file_name)
                print('å·²åˆ é™¤æ–‡ä»¶å¤¹:\n' + file_path)
                shutil.rmtree(file_path)
            st.success("æ‰€æœ‰ç¼“å­˜æ–‡ä»¶å·²æˆåŠŸåˆ é™¤ã€‚")

    st.session_state.openai_base = openai_api_base
    st.session_state.openai_key = openai_api_key
    st.session_state.kimi_key = kimi_api_key
    st.session_state.proxy_on = proxy_on
    st.session_state.w_model_option = w_model_option
    st.session_state.w_name = w_version

with tab3:
    with open(log_dir, 'r', encoding='utf-8') as file:
        markdown_log = file.read()
    st.write(markdown_log)
    st.caption('ç”±æœ¬åœ°log.mdè¯»å–åŠ è½½')
    st.write('')
    st.write('')
    st.write('')
    st.write('')
    st.write('')
    st.write('')
    st.write(markdown_content)
    st.caption('ç”±æœ¬åœ°README.mdè¯»å–åŠ è½½')
