import os
import toml
import time
import torch
import datetime
import streamlit as st
import streamlit_antd_components as sac
from project.utils.utils2 import (file_to_mp3, openai_whisper_result, faster_whisper_result, translate, local_translate,
                                  generate_srt_from_result, generate_srt_from_result_2, srt_mv, show_video, parse_srt_file,
                                  convert_to_srt, srt_to_ass, srt_to_stl, srt_to_vtt, check_cuda_support, check_ffmpeg,
                                  add_font_settings)


def video():
    project_dir = os.path.dirname(os.path.abspath(__file__)).replace("\\", "/")
    config_dir = project_dir + "/config/"  # é…ç½®æ–‡ä»¶
    cache_dir = project_dir + "/cache/"  # æœ¬åœ°ç¼“å­˜
    model_dir = project_dir.replace("project", "model")

    api_config = toml.load(config_dir + "api.toml")  # åŠ è½½APIé…ç½®
    openai_key = api_config["GPT"]["openai_key"]
    openai_base = api_config["GPT"]["openai_base"]
    kimi_key = api_config["KIMI"]["kimi_key"]
    kimi_base = api_config["KIMI"]["kimi_base"]
    deepseek_key = api_config["DEEPSEEK"]["deepseek_key"]
    deepseek_base = api_config["DEEPSEEK"]["deepseek_base"]
    chatglm_key = api_config["CHATGLM"]["chatglm_key"]
    chatglm_base = api_config["CHATGLM"]["chatglm_base"]
    local_key = api_config["LOCAL"]["api_key"]
    local_base = api_config["LOCAL"]["base_url"]
    local_model = api_config["LOCAL"]["model_name"]

    video_config = toml.load(config_dir + "video.toml")  # åŠ è½½videoé…ç½®
    openai_whisper_api = video_config["WHISPER"]["openai_whisper_api"]  # openai_whisperé…ç½®
    faster_whisper_model = video_config["WHISPER"]["faster_whisper_model_default"]  # faster_whisperé…ç½®
    faster_whisper_local = video_config["WHISPER"]["faster_whisper_model_local"]  # æœ¬åœ°æ¨¡å‹åŠ è½½
    faster_whisper_local_path = video_config["WHISPER"]["faster_whisper_model_local_path"]  # æœ¬åœ°æ¨¡å‹è·¯å¾„
    gpu_setting = video_config["WHISPER"]["gpu"]
    vad_setting = video_config["WHISPER"]["vad"]
    lang_setting = video_config["WHISPER"]["lang"]
    translate_setting = video_config["TRANSLATE"]["translate_model"]
    language1_setting = video_config["TRANSLATE"]["language1"]
    language2_setting = video_config["TRANSLATE"]["language2"]
    wait_time_setting = video_config["TRANSLATE"]["wait_time"]
    subtitle_model_setting = video_config["SUBTITLE"]["subtitle_model"]
    font_setting = video_config["SUBTITLE"]["font"]
    soft_font_size_setting = video_config["SUBTITLE"]["soft_font_size"]
    hard_font_size_setting = video_config["SUBTITLE"]["hard_font_size"]
    font_color_setting = video_config["SUBTITLE"]["font_color"]
    min_vad_setting = video_config["MORE"]["min_vad"]
    beam_size_setting = video_config["MORE"]["beam_size"]
    whisper_prompt_setting = video_config["MORE"]["whisper_prompt"]
    temperature_setting = video_config["MORE"]["temperature"]
    crf_setting = video_config["MORE"]["crf"]
    quality_setting = video_config["MORE"]["quality"]
    ffmpeg_setting = video_config["MORE"]["ffmpeg"]
    log_setting = video_config["MORE"]["log"]

    options = {'faster-whisper': {'models': {'tiny': 0, 'tiny.en': 1, 'base': 2, 'base.en': 3, 'small': 4,
                                             'small.en': 5, 'medium': 6, 'medium.en': 7, 'large-v1': 8,
                                             'large-v2': 9, 'large-v3': 10, 'large': 11, 'distil-small.en': 12,
                                             'distil-medium.en': 13, 'distil-large-v2': 14,
                                             'distil-large-v3': 15}}}

    with st.sidebar:
        uploaded_file = st.file_uploader("è¯·åœ¨è¿™é‡Œä¸Šä¼ è§†é¢‘ï¼š", type=['mp4', 'mov', 'avi', 'm4v', 'webm', 'flv', 'ico'], label_visibility="collapsed")

    st.subheader("å…¨è‡ªåŠ¨è§†é¢‘ç¿»è¯‘")
    st.caption("AI Auto Video Translation")

    name = sac.segmented(
        items=[
            sac.SegmentedItem(label="å‚æ•°è®¾ç½®", icon="gear-wide-connected"),
            sac.SegmentedItem(label="è§†é¢‘ç”Ÿæˆ", icon="camera-video"),
            sac.SegmentedItem(label="GitHub", icon="github", href="https://github.com/Chenyme/Chenyme-AAVT"),
        ], align='center', size='sm', radius=20, color='red', divider=False, use_container_width=True
    )

    if name == 'å‚æ•°è®¾ç½®':
        col1, col2 = st.columns([0.65, 0.35], gap="medium")
        with col1:
            with st.expander("**è¯†åˆ«è®¾ç½®**", expanded=True):
                model = st.selectbox("Whisperæ¨¡å¼", ("OpenAI-API æ¥å£è°ƒç”¨", "Faster-Whisper æœ¬åœ°éƒ¨ç½²"), index=0 if openai_whisper_api else 1, help="`OpenAI-API æ¥å£è°ƒç”¨`ï¼šä½¿ç”¨OpenAIçš„å®˜æ–¹æ¥å£è¿›è¡Œè¯†åˆ«ï¼Œæ–‡ä»¶é™åˆ¶25MBï¼ˆä¸æ˜¯ä¸Šä¼ è§†é¢‘æ–‡ä»¶ï¼Œæ˜¯è¯¥é¡¹ç›®è½¬æ¢åçš„éŸ³é¢‘æ–‡ä»¶ï¼Œå¯ä»¥å‰å¾€CacheæŸ¥çœ‹æ¯æ¬¡çš„å¤§å°ï¼‰ï¼Œè¿‡å¤§ä¼šå¯¼è‡´ä¸Šä¼ å¤±è´¥\n\n`Faster-Whisper æœ¬åœ°éƒ¨ç½²`ï¼šæœ¬åœ°è¯†åˆ«å­—å¹•ï¼Œæ— éœ€æ‹…å¿ƒå¤§å°é™åˆ¶ã€‚è¯·æ³¨æ„ï¼Œè‹¥ç½‘ç»œä¸ä½³è¯·å¯ç”¨ä¸‹æ–¹çš„æœ¬åœ°æ¨¡å‹åŠ è½½")
                if model == "OpenAI-API æ¥å£è°ƒç”¨":
                    openai_whisper_api = True
                    video_config["WHISPER"]["openai_whisper_api"] = openai_whisper_api
                    local_on = False
                    video_config["WHISPER"]["faster_whisper_model_local"] = local_on

                else:
                    openai_whisper_api = False
                    video_config["WHISPER"]["openai_whisper_api"] = openai_whisper_api
                    local_on = st.checkbox('æœ¬åœ°åŠ è½½æ¨¡å‹', faster_whisper_local, help="ä½¿ç”¨æœ¬åœ°ä¸‹è½½å¥½çš„æ¨¡å‹è¿›è¡Œè½¬å½•")
                    video_config["WHISPER"]["faster_whisper_model_local"] = local_on

                if not openai_whisper_api:
                    col3, col4, col5 = st.columns([0.3, 0.4, 0.4])
                    with col3:
                        gpu = st.toggle('GPUåŠ é€Ÿ', disabled=not torch.cuda.is_available(), help='cudaã€pytorchæ­£ç¡®åæ‰å¯ä½¿ç”¨ï¼', value=gpu_setting)
                        vad = st.toggle('VADè¾…åŠ©', help='å¯ç”¨è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVADï¼‰ä»¥è¿‡æ»¤æ‰æ²¡æœ‰è¯­éŸ³çš„éŸ³é¢‘éƒ¨åˆ†', value=vad_setting)

                    with col4:
                        language = ['è‡ªåŠ¨è¯†åˆ«', 'zh', 'en', 'ja', 'ko', 'it', 'de']  # language
                        index = language.index(lang_setting)
                        lang = st.selectbox('è§†é¢‘è¯­è¨€', language, index=index, help="å¼ºåˆ¶æŒ‡å®šè§†é¢‘è¯­è¨€ä¼šæé«˜è¯†åˆ«å‡†ç¡®åº¦ï¼Œä½†ä¹Ÿå¯èƒ½ä¼šé€ æˆè¯†åˆ«å‡ºé”™ã€‚")

                    with col5:
                        if local_on:
                            model_names = os.listdir(model_dir)
                            path = faster_whisper_local_path

                            try:
                                index_model = model_names.index(path.replace(model_dir + '/', ''))
                                local_option = st.selectbox('æœ¬åœ°æ¨¡å‹', model_names, index=index_model, help="æ¨¡å‹ä¸‹è½½ï¼šhttps://huggingface.co/Systran")
                            except:
                                local_option = st.selectbox('æœ¬åœ°æ¨¡å‹', model_names, index=0, help="æ¨¡å‹ä¸‹è½½ï¼šhttps://huggingface.co/Systran")
                            local_model_path = model_dir + '/' + local_option
                            video_config["WHISPER"]["faster_whisper_model_local_path"] = local_model_path

                        elif not local_on:
                            model_option = st.selectbox('è¯†åˆ«æ¨¡å‹', list(options['faster-whisper']['models'].keys()), index=options['faster-whisper']['models'][faster_whisper_model], help="æ¨èlargeæ¨¡å‹")
                            video_config["WHISPER"]["faster_whisper_model_default"] = model_option

                    video_config["WHISPER"]["gpu"] = gpu
                    video_config["WHISPER"]["vad"] = vad
                    video_config["WHISPER"]["lang"] = lang

            with st.expander("**ç¿»è¯‘è®¾ç½®**", expanded=True):
                translate_option = sac.cascader(items=[
                    sac.CasItem('æ— éœ€ç¿»è¯‘'),
                    sac.CasItem('æœ¬åœ°æ¨¡å‹', icon='house-up-fill'),
                    sac.CasItem('ChatGPT-OpenAI', icon='node-plus-fill', children=[
                        sac.CasItem('gpt-3.5-turbo', icon='robot'),
                        sac.CasItem('gpt-4o', icon='robot'),
                        sac.CasItem('gpt-4', icon='robot')]),
                    sac.CasItem('Moonshot-æœˆä¹‹æš—é¢', icon='node-plus-fill', children=[
                        sac.CasItem('kimi-moonshot-v1-8k', icon='robot'),
                        sac.CasItem('kimi-moonshot-v1-32k', icon='robot'),
                        sac.CasItem('kimi-moonshot-v1-128k', icon='robot')]),
                    sac.CasItem('ChatGLM-æ™ºè°±AI', icon='node-plus-fill', children=[
                        sac.CasItem('glm-3-turbo', icon='robot'),
                        sac.CasItem('glm-4v', icon='robot'),
                        sac.CasItem('glm-4', icon='robot')]),
                    sac.CasItem('DeepSeek-æ·±åº¦æ±‚ç´¢', icon='node-plus-fill', children=[
                        sac.CasItem('deepseek-v2', icon='robot')]),
                ], label='<span style="font-size: 14px;">ç¿»è¯‘å¼•æ“</span>', search=True, index=translate_setting, return_index=True)
                video_config["TRANSLATE"]["translate_model"] = translate_option

                if translate_option != [0]:
                    language = ['ä¸­æ–‡', 'English', 'æ—¥æœ¬èª', 'í•œêµ­ì¸', 'Italiano', 'Deutsch']

                    col3, col4, col5 = st.columns(3)
                    with col3:
                        language1 = st.selectbox('åŸå§‹è¯­è¨€', language, index=language.index(language1_setting))
                    with col4:
                        language2 = st.selectbox('ç›®æ ‡è¯­è¨€', language, index=language.index(language2_setting))
                    with col5:
                        wait_time = st.number_input('ç¿»è¯‘é—´éš”(s)', min_value=0.0, max_value=5.0, value=wait_time_setting, step=0.1, help="æ¯æ¬¡APIè°ƒç”¨çš„é—´éš”ã€‚\n\n å½“ä½ çš„è§†é¢‘æ¯”è¾ƒé•¿ï¼Œå­—å¹•å¾ˆå¤šæ—¶ï¼Œå¯¼è‡´ç¿»è¯‘æ—¶ä¼šä¸€ç›´åå¤è°ƒç”¨ API å¤ªå¤šæ¬¡ï¼Œè¿™ä¼šè¾¾åˆ°æ¯åˆ†é’Ÿé€Ÿç‡æœ€å¤§é™åˆ¶ã€‚å½“é‡åˆ°æŠ¥é”™429ï¼Œå¦‚ï¼š`Too Many Requests`ã€`RateLimitError`è¿™ç§é€Ÿç‡æŠ¥é”™ï¼Œé‚£å°±éœ€è¦é€‚å½“å¢å¤§é—´éš”ã€‚")

                    video_config["TRANSLATE"]["language1"] = language1
                    video_config["TRANSLATE"]["language2"] = language2
                    video_config["TRANSLATE"]["wait_time"] = wait_time

            with st.expander("**å­—å¹•è®¾ç½®**", expanded=True):
                with open(config_dir + 'font_data.txt', 'r', encoding='utf-8') as file:
                    lines = file.readlines()
                    fonts = [line.strip() for line in lines]

                col3, col4 = st.columns(2)
                with col3:
                    subtitle_model = st.selectbox('å­—å¹•æ¨¡å¼', ["ç¡¬å­—å¹•", "è½¯å­—å¹•"], index=["ç¡¬å­—å¹•", "è½¯å­—å¹•"].index(subtitle_model_setting), help="è¯·æ³¨æ„ï¼šç”±äºè½¯å­—å¹•ä¼šå¯¼è‡´éƒ¨åˆ†å­—ä½“ä¼šæ— æ³•æ­£å¸¸æ˜¾ç¤ºï¼Œå› æ­¤å¯èƒ½ä¼šå‡ºç°ä¹±ç ï¼\n\n åŒæ—¶ï¼Œæ‚¨æ— æ³•åœ¨ç½‘é¡µä¸­é¢„è§ˆå­—å¹•æ•ˆæœï¼Œè¯·æ‰“å¼€æ–‡ä»¶å¤¹è®¿é—®åŸè§†é¢‘å¹¶ä½¿ç”¨æ”¯æŒå¤–æŒ‚å­—å¹•çš„è§†é¢‘æ’­æ”¾å™¨æŒ‚è½½å­—å¹•æŸ¥çœ‹æ•ˆæœï¼")
                with col4:
                    font = st.selectbox('å­—å¹•å­—ä½“', fonts, index=fonts.index(font_setting), help="æ‰€æœ‰å­—ä½“å‡ä»ç³»ç»Ÿè¯»å–åŠ è½½ï¼Œæ”¯æŒç”¨æˆ·è‡ªè¡Œå®‰è£…å­—ä½“ã€‚è¯·æ³¨æ„å•†ç”¨é£é™©ï¼")

                col3, col4 = st.columns([0.9, 0.1], gap="medium")
                with col3:
                    if subtitle_model == "è½¯å­—å¹•":
                        soft_font_size = st.number_input('è½¯å­—å¹•å¤§å°', min_value=30, max_value=90, value=soft_font_size_setting, step=1, help="æ¨èå¤§å°ï¼š60")
                        video_config["SUBTITLE"]["soft_font_size"] = soft_font_size
                    else:
                        hard_font_size = st.number_input('ç¡¬å­—å¹•å¤§å°', min_value=1, max_value=36, value=hard_font_size_setting, step=1, help="æ¨èå¤§å°ï¼š18")
                        video_config["SUBTITLE"]["hard_font_size"] = hard_font_size
                with col4:
                    font_color = st.color_picker('é¢œè‰²', value=font_color_setting)

                video_config["SUBTITLE"]["subtitle_model"] = subtitle_model
                video_config["SUBTITLE"]["font"] = font
                video_config["SUBTITLE"]["font_color"] = font_color

            with st.expander("**é«˜çº§è®¾ç½®**", expanded=False):
                col3, col4 = st.columns([0.5, 0.5], gap="medium")
                with col3:
                    min_vad = st.number_input("VADé™éŸ³æ£€æµ‹(ms)", min_value=100, max_value=5000, value=min_vad_setting, step=100, disabled=openai_whisper_api, help="`min_silence_duration_ms`å‚æ•°ï¼Œæœ€å°é™éŸ³æŒç»­æ—¶é—´ï¼Œå¯ç”¨VADè¾…åŠ©åç”Ÿæ•ˆï¼")
                    beam_size = st.number_input("æŸæœç´¢å¤§å°", min_value=1, max_value=20, value=beam_size_setting, step=1, disabled=openai_whisper_api, help="`beam_size`å‚æ•°ã€‚ç”¨äºå®šä¹‰æŸæœç´¢ç®—æ³•ä¸­æ¯ä¸ªæ—¶é—´æ­¥ä¿ç•™çš„å€™é€‰é¡¹æ•°é‡ã€‚æŸæœç´¢ç®—æ³•é€šè¿‡åœ¨æ¯ä¸ªæ—¶é—´æ­¥é€‰æ‹©æœ€æœ‰å¯èƒ½çš„å€™é€‰é¡¹æ¥æ„å»ºæœç´¢æ ‘ï¼Œå¹¶æ ¹æ®å€™é€‰é¡¹çš„å¾—åˆ†è¿›è¡Œæ’åºå’Œå‰ªæã€‚è¾ƒå¤§çš„beam_sizeå€¼ä¼šä¿ç•™æ›´å¤šçš„å€™é€‰é¡¹ï¼Œæ‰©å¤§æœç´¢ç©ºé—´ï¼Œå¯èƒ½æé«˜ç”Ÿæˆç»“æœçš„å‡†ç¡®æ€§ï¼Œä½†ä¹Ÿä¼šå¢åŠ è®¡ç®—å¼€é”€ã€‚ç›¸åï¼Œè¾ƒå°çš„beam_sizeå€¼ä¼šå‡å°‘è®¡ç®—å¼€é”€ï¼Œä½†å¯èƒ½å¯¼è‡´æœç´¢è¿‡æ—©åœ°æ”¾å¼ƒæœ€ä½³åºåˆ—ã€‚")
                    whisper_prompt = st.text_input("Whisperæç¤ºè¯", value=whisper_prompt_setting, help="è‹¥æ‚¨æ— æ›´å¥½çš„Whisperæç¤ºè¯ï¼Œè¯·å‹¿éšæ„ä¿®æ”¹ï¼å¦åˆ™ä¼šå½±å“æ–­å¥æ•ˆæœ")
                    temperature = st.number_input("Whisperæ¸©åº¦", min_value=0.0, max_value=1.0, value=temperature_setting, step=0.1, help="Whisperè½¬å½•æ—¶æ¨¡å‹æ¸©åº¦ï¼Œè¶Šå¤§éšæœºæ€§ï¼ˆåˆ›é€ æ€§ï¼‰è¶Šé«˜ã€‚")
                with col4:
                    crf = st.selectbox("FFmpeg-æ’å®šé€Ÿç‡å› å­", [0, 18, 23, 28], index=[0, 18, 23, 28].index(crf_setting), help="CRF å€¼çš„èŒƒå›´é€šå¸¸ä¸º 0 åˆ° 51ï¼Œæ•°å€¼è¶Šä½ï¼Œè´¨é‡è¶Šé«˜ã€‚å»ºè®®å€¼ï¼š\n- `0`: æ— æŸå‹ç¼©ï¼Œè´¨é‡æœ€é«˜ï¼Œæ–‡ä»¶æœ€å¤§ã€‚\n- `18`: è§†è§‰ä¸Šæ¥è¿‘æ— æŸï¼Œéå¸¸é«˜çš„è´¨é‡ï¼Œæ–‡ä»¶è¾ƒå¤§ã€‚\n- `23`: é»˜è®¤å€¼ï¼Œè´¨é‡å’Œæ–‡ä»¶å¤§å°çš„å¹³è¡¡ç‚¹ã€‚\n- `28`: è¾ƒä½çš„è´¨é‡ï¼Œæ–‡ä»¶è¾ƒå°ã€‚")
                    quality_list = ["ultrafast", "superfast", "veryfast", "faster", "fast", "medium", "slow", "slower", "veryslow", "placebo"]
                    quality = st.selectbox("FFmpeg-ç¼–ç å™¨é¢„è®¾(è´¨é‡)", quality_list, index=quality_list.index(quality_setting), help="ç¼–ç å™¨é¢„è®¾(è´¨é‡quality)ï¼Œé»˜è®¤å€¼ä¸º `medium`ã€‚æ³¨æ„ï¼Œä¸‹é¢æœ‰äº›å€¼æ˜¯ä¸å¯ä½¿ç”¨çš„ï¼Œè‹¥ä½ ä¸äº†è§£ï¼Œè¯·å‹¿ä¿®æ”¹ï¼å¯é€‰å€¼åŒ…æ‹¬ï¼š\n- `ultrafast`: æœ€å¿«çš„ç¼–ç é€Ÿåº¦ï¼Œä½†è´¨é‡æœ€ä½ï¼Œæ–‡ä»¶æœ€å¤§ã€‚\n- `superfast`: éå¸¸å¿«çš„ç¼–ç é€Ÿåº¦ï¼Œè´¨é‡å’Œæ–‡ä»¶å¤§å°æœ‰æ‰€æå‡ã€‚\n- `veryfast`: å¾ˆå¿«çš„ç¼–ç é€Ÿåº¦ï¼Œé€‚ç”¨äºå®æ—¶ç¼–ç æˆ–éœ€è¦å¿«é€Ÿå¤„ç†çš„æƒ…å†µã€‚\n- `faster`: æ¯”è¾ƒå¿«çš„ç¼–ç é€Ÿåº¦ï¼Œè´¨é‡è¿›ä¸€æ­¥æé«˜ã€‚\n- `fast`: å¿«é€Ÿç¼–ç é€Ÿåº¦ï¼Œè´¨é‡è¾ƒå¥½ã€‚\n- `medium`: é»˜è®¤é¢„è®¾ï¼Œç¼–ç é€Ÿåº¦å’Œè´¨é‡çš„å¹³è¡¡ç‚¹ã€‚\n- `slow`: è¾ƒæ…¢çš„ç¼–ç é€Ÿåº¦ï¼Œè¾“å‡ºè´¨é‡æ›´é«˜ï¼Œæ–‡ä»¶æ›´å°ã€‚\n- `slower`: æ›´æ…¢çš„ç¼–ç é€Ÿåº¦ï¼Œè´¨é‡è¿›ä¸€æ­¥æé«˜ã€‚\n- `veryslow`: éå¸¸æ…¢çš„ç¼–ç é€Ÿåº¦ï¼Œè´¨é‡æœ€é«˜ï¼Œæ–‡ä»¶æœ€å°ã€‚\n- `placebo`: ææ…¢çš„ç¼–ç é€Ÿåº¦ï¼Œè´¨é‡å¾®å°æå‡ï¼Œä¸æ¨èä½¿ç”¨ï¼Œé™¤éå¯¹è´¨é‡æœ‰æé«˜è¦æ±‚ä¸”ä¸åœ¨æ„ç¼–ç æ—¶é—´ã€‚")
                    ffmpeg = st.selectbox("FFmpeg-ç¼–ç å™¨", ["h264_nvenc", "libx264"], index=["h264_nvenc", "libx264"].index(ffmpeg_setting), help="CUDAå¯ç”¨æ—¶ï¼Œå¯é€‰æ‹©h264_nvencã€‚å¦åˆ™é»˜è®¤libx264ï¼Œæ³¨æ„h264_nvencè´¨é‡è¿‡é«˜ï¼Œè¾“å‡ºæ–‡ä»¶ä¼šå¾ˆå¤§")
                    log = st.selectbox("FFmpeg-æ—¥å¿—çº§åˆ«", ["quiet", "panic", "fatal", "error", "warning", "info", "verbose", "debug", "trace"], index=["quiet", "panic", "fatal", "error", "warning", "info", "verbose", "debug", "trace"].index(log_setting), help="FFmpegè¾“å‡ºæ—¥å¿—ã€‚\n- **quiet**ï¼šæ²¡æœ‰è¾“å‡ºæ—¥å¿—ã€‚\n- **panic**ï¼šä»…åœ¨ä¸å¯æ¢å¤çš„è‡´å‘½é”™è¯¯å‘ç”Ÿæ—¶è¾“å‡ºæ—¥å¿—ã€‚\n- **fatal**ï¼šä»…åœ¨è‡´å‘½é”™è¯¯å‘ç”Ÿæ—¶è¾“å‡ºæ—¥å¿—ã€‚\n- **error**ï¼šåœ¨é”™è¯¯å‘ç”Ÿæ—¶è¾“å‡ºæ—¥å¿—ã€‚\n- **warning**ï¼šåœ¨è­¦å‘Šçº§åˆ«åŠä»¥ä¸Šçš„äº‹ä»¶å‘ç”Ÿæ—¶è¾“å‡ºæ—¥å¿—ã€‚\n- **info**ï¼šåœ¨ä¿¡æ¯çº§åˆ«åŠä»¥ä¸Šçš„äº‹ä»¶å‘ç”Ÿæ—¶è¾“å‡ºæ—¥å¿—ã€‚\n- **verbose**ï¼šè¾“å‡ºè¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬è°ƒè¯•å’Œä¿¡æ¯çº§åˆ«çš„æ—¥å¿—ã€‚\n- **debug**ï¼šè¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼Œéå¸¸è¯¦ç»†çš„æ—¥å¿—è¾“å‡ºã€‚\n- **trace**ï¼šæœ€è¯¦ç»†çš„æ—¥å¿—è¾“å‡ºï¼Œç”¨äºæå…¶è¯¦ç»†çš„è°ƒè¯•ã€‚")

                video_config["MORE"]["min_vad"] = min_vad
                video_config["MORE"]["beam_size"] = beam_size
                video_config["MORE"]["whisper_prompt"] = whisper_prompt
                video_config["MORE"]["temperature"] = temperature
                video_config["MORE"]["crf"] = crf
                video_config["MORE"]["quality"] = quality
                video_config["MORE"]["ffmpeg"] = ffmpeg
                video_config["MORE"]["log"] = log

        with col2:
            if st.button("ä¿å­˜æ‰€æœ‰å‚æ•°", type="primary", use_container_width=True):
                sac.divider(label='**å‚æ•°æç¤º**', icon='activity', align='center', color='gray')
                with open(config_dir + '/video.toml', 'w', encoding='utf-8') as file:
                    toml.dump(video_config, file)
                sac.alert(
                    label='**å‚æ•°è®¾ç½® å·²ä¿å­˜**',
                    description='**æ‰€æœ‰å‚æ•°å…¨éƒ¨ä¿å­˜å®Œæ¯•**',
                    size='lg', radius=20, icon=True, closable=True, color='success')
            else:
                sac.divider(label='**å‚æ•°æç¤º**', icon='activity', align='center', color='gray')
                sac.alert(
                    label='**å‚æ•°è®¾ç½® å¯èƒ½æœªä¿å­˜**',
                    description='é‡æ–°è®¾ç½®åè¯·ç‚¹å‡»ä¿å­˜',
                    size='lg', radius=20, icon=True, closable=True, color='error')

            if check_ffmpeg():
                if check_cuda_support():
                    sac.alert(
                        label='**FFmpeg GPUåŠ é€Ÿæ­£å¸¸**',
                        description='FFmpeg**åŠ é€Ÿå¯ç”¨**',
                        size='lg', radius=20, icon=True, closable=True, color='success')
                else:
                    sac.alert(
                        label='**FFmpeg çŠ¶æ€æ­£å¸¸**',
                        description='å·²**æˆåŠŸæ£€æµ‹**åˆ°FFmpeg',
                        size='lg', radius=20, icon=True, closable=True, color='success')
            else:
                sac.alert(
                    label='**FFmpeg çŠ¶æ€é”™è¯¯**',
                    description='**æœªæ£€æµ‹åˆ°**FFmpeg',
                    size='lg', radius=20, icon=True, closable=True, color='success')

            if not openai_whisper_api:
                if vad:
                    sac.alert(
                        label='**VADè¾…åŠ© å·²å¼€å¯**',
                        description='å°†ä¼š**æ£€æµ‹è¯­éŸ³æ´»åŠ¨**',
                        size='lg', radius=20, icon=True, closable=True, color='success')

            if openai_whisper_api:
                sac.alert(
                    label='**Whipser APIè°ƒç”¨å·²å¼€å¯**',
                    description='ç¡®ä¿**OPENAIç›¸å…³é…ç½®ä¸ä¸ºç©º**',
                    size='lg', radius=20, icon=True, closable=True, color='warning')

            if not openai_whisper_api:
                if gpu:
                    sac.alert(
                        label='**GPUåŠ é€Ÿæ¨¡å¼ å·²å¼€å¯**',
                        description='**è‹¥æœªCUDA11è¯·å‚é˜…[AAVT](https://zwho5v3j233.feishu.cn/wiki/OGcrwinzhi88MkkvEMVcLkDgnzc?from=from_copylink)**',
                        size='lg', radius=20, icon=True, closable=True, color='warning')

            if not openai_whisper_api:
                if local_on:
                    sac.alert(
                        label='**Whisper æœ¬åœ°åŠ è½½å·²å¼€å¯**',
                        description='[æ¨¡å‹ä¸‹è½½](https://huggingface.co/Systran) | [ä½¿ç”¨æ–‡æ¡£](https://zwho5v3j233.feishu.cn/wiki/OGcrwinzhi88MkkvEMVcLkDgnzc?from=from_copylink)',
                        size='lg', radius=20, icon=True, closable=True, color='warning')

            if translate_option == [1]:
                sac.alert(
                    label='**æœ¬åœ°LLMè°ƒç”¨ å·²å¼€å¯**',
                    description="è¯·**ç¡®ä¿ç›¸å…³å‚æ•°æ— è¯¯**",
                    size='lg', radius=20, icon=True, closable=True, color='warning')

            if subtitle_model == "è½¯å­—å¹•":
                sac.alert(
                    label='**è½¯å­—å¹• å·²å¼€å¯**',
                    description='è½¯å­—å¹•**æ— æ³•é¢„è§ˆæ•ˆæœ**',
                    size='lg', radius=20, icon=True, closable=True, color='warning')

            if not torch.cuda.is_available():
                sac.alert(
                    label='**CUDA/Pytorch é”™è¯¯**',
                    description='è¯·æ£€æŸ¥ï¼**ä»…ä½¿ç”¨CPUè¯·å¿½ç•¥**',
                    size='lg', radius=20, icon=True, closable=True, color='error')

            if ffmpeg != "libx264":
                if not check_cuda_support():
                    sac.alert(
                        label='**ç¼–ç å™¨æ— æ•ˆ è¯·æ¢å›libx264**',
                        description='**æœªæ£€æµ‹åˆ°**h264_nvencç¼–ç å™¨',
                        size='lg', radius=20, icon=True, closable=True, color='error')
                else:
                    sac.alert(
                        label='**ç¼–ç å™¨è®¾ç½® æˆåŠŸ**',
                        description='**æ£€æµ‹åˆ°**h264_nvencç¼–ç å™¨',
                        size='lg', radius=20, icon=True, closable=True, color='success')

            sac.divider(label='POWERED BY @CHENYME', icon="lightning-charge", align='center', color='gray', key="1")

    if name == 'è§†é¢‘ç”Ÿæˆ':
        with st.expander("video_preview", expanded=True):
            col5, col6 = st.columns(2, gap="medium")
        col1, col2 = st.columns([0.8, 0.2])

        with col2:
            with st.expander("setting", expanded=True):
                font_size_setting = hard_font_size_setting
                if subtitle_model_setting == "è½¯å­—å¹•":
                    font_size_setting = soft_font_size_setting

                sac.divider(label='æ–¹æ¡ˆä¸€ï¼šä¸€é”®ç”Ÿæˆ', icon='1-square', align='center', color='gray')
                if st.button("ä¸€é”®ç”Ÿæˆè§†é¢‘", type="primary", use_container_width=True, help="è¿™é‡Œæ˜¯æ–¹æ¡ˆä¸€ï¼šæ‚¨å¯ä»¥ç›´æ¥ç”Ÿæˆç¿»è¯‘å¹¶åˆå¹¶å¥½çš„è§†é¢‘æ–‡ä»¶ã€‚\n\nå¦‚æœè§‰å¾—ç”Ÿæˆçš„å­—å¹•ä¸ç¬¦åˆé¢„æœŸï¼Œå¯ä»¥ç»§ç»­ä¿®æ”¹å­—å¹•ç‚¹å‡»ä¸‹æ–¹`åˆå¹¶å­—å¹•`æŒ‰é’®è¿›è¡Œåˆå¹¶"):
                    if uploaded_file is not None:
                        st.session_state.video_name = "uploaded." + uploaded_file.name.split('.')[-1]
                        time1 = time.time()
                        msg = st.toast('å¼€å§‹ç”Ÿæˆ!')
                        msg.toast('æ­£åœ¨è¿›è¡Œè§†é¢‘æå–ğŸ“½ï¸')

                        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H-%M-%S")
                        output_file = cache_dir + current_time
                        os.makedirs(output_file)
                        with open(output_file + '/' + st.session_state.video_name, "wb") as file:
                            file.write(uploaded_file.getbuffer())
                        print(f"- æœ¬æ¬¡ä»»åŠ¡ç›®å½•ï¼š{output_file}")
                        file_to_mp3(log_setting, st.session_state.video_name, output_file)

                        time2 = time.time()
                        msg.toast('æ­£åœ¨è¯†åˆ«è§†é¢‘å†…å®¹ğŸ”')
                        if openai_whisper_api:
                            result = openai_whisper_result(openai_key, openai_base, output_file, whisper_prompt_setting, temperature_setting)
                        else:
                            device = 'cuda' if gpu_setting else 'cpu'
                            model = faster_whisper_model
                            if faster_whisper_local:
                                model = faster_whisper_local_path
                            result = faster_whisper_result(output_file, device, model, whisper_prompt_setting, temperature_setting, vad_setting, lang_setting, beam_size_setting, min_vad_setting)

                        time3 = time.time()
                        translation_dict = {
                            tuple([0]): 'æ— éœ€ç¿»è¯‘',
                            tuple([1]): 'æœ¬åœ°æ¨¡å‹',
                            tuple([2, 3]): 'gpt-3.5-turbo',
                            tuple([2, 4]): 'gpt-4o',
                            tuple([2, 5]): 'gpt-4',
                            tuple([6, 7]): 'moonshot-v1-8k',
                            tuple([6, 8]): 'moonshot-v1-32k',
                            tuple([6, 9]): 'moonshot-v1-128k',
                            tuple([10, 11]): 'glm-3-turbo',
                            tuple([10, 12]): 'glm-4v',
                            tuple([10, 13]): 'glm-4',
                            tuple([14, 15]): 'deepseek-chat'
                        }
                        translate_option = translation_dict[tuple(translate_setting)]

                        if translate_option != 'æ— éœ€ç¿»è¯‘':
                            print("***æ­£åœ¨æ‰§è¡Œç¿»è¯‘***\n")
                            msg.toast('æ­£åœ¨ç¿»è¯‘æ–‡æœ¬ğŸ¤–')
                            print("- ç¿»è¯‘æ¨¡å‹:" + translate_option)
                            if translate_option == 'gpt-3.5-turbo' or translate_option == 'gpt-4o':
                                result = translate(openai_key, openai_base, translate_option, result, language1_setting, language2_setting, wait_time_setting)
                            elif 'kimi' in translate_option:
                                result = translate(kimi_key, kimi_base, translate_option, result, language1_setting, language2_setting, wait_time_setting)
                            elif 'glm' in translate_option:
                                result = translate(chatglm_key, chatglm_base, translate_option, result, language1_setting, language2_setting, wait_time_setting)
                            elif 'deepseek' in translate_option:
                                result = translate(deepseek_key, deepseek_base, translate_option, result, language1_setting, language2_setting, wait_time_setting)
                            elif translate_option == 'æœ¬åœ°æ¨¡å‹':
                                result = local_translate(local_key, local_base, local_model, result, language1_setting, language2_setting)
                            print(" ")

                        time4 = time.time()
                        msg.toast('æ­£åœ¨ç”ŸæˆSRTå­—å¹•æ–‡ä»¶ğŸ“ƒ')
                        print("***æ­£åœ¨ç”ŸæˆSRTå­—å¹•æ–‡ä»¶***\n")
                        srt_content = generate_srt_from_result(result)
                        srt_content_style = generate_srt_from_result_2(result, font_setting, font_size_setting, font_color_setting)
                        with open(output_file + "/output.srt", 'w', encoding='utf-8') as srt_file:
                            srt_file.write(srt_content)
                        with open(output_file + "/output_with_style.srt", 'w', encoding='utf-8') as srt_file:
                            srt_file.write(srt_content_style)
                        st.session_state.output_file = output_file

                        time5 = time.time()
                        st.toast('æ­£åœ¨åˆå¹¶è§†é¢‘ï¼Œè¯·è€å¿ƒç­‰å¾…ç”Ÿæˆâš™ï¸')
                        print("***æ­£åœ¨åˆå¹¶è§†é¢‘***\n")
                        srt_mv(log_setting, st.session_state.video_name, crf_setting, quality_setting, ffmpeg_setting, st.session_state.output_file, font_setting, font_size_setting, font_color_setting, subtitle_model_setting)

                        time6 = time.time()
                        print("***å·²å®Œæˆ***\n")
                        st.toast("ä»»åŠ¡å·²å®Œæˆï¼", icon=":material/task_alt:")
                        total_time = time6 - time1
                        st.session_state.time = f"{total_time:.2f}"
                    else:
                        st.toast("æœªæ£€æµ‹åˆ°æ–‡ä»¶", icon=":material/error:")

                sac.divider(label='æ–¹æ¡ˆäºŒï¼šåˆ†æ®µåˆæˆ', icon='2-square', align='center', color='gray')
                if st.button("ç”Ÿæˆå­—å¹•", type="primary", use_container_width=True, help="è¿™é‡Œæ˜¯æ–¹æ¡ˆäºŒï¼šæ‚¨å¯ä»¥å…ˆä»…ç”Ÿæˆå­—å¹•æ–‡ä»¶ï¼Œè°ƒæ•´å¥½åå†ç»§ç»­ç‚¹å‡»ä¸‹æ–¹`åˆå¹¶å­—å¹•`è¿›è¡Œåˆå¹¶"):
                    if uploaded_file is not None:
                        st.session_state.video_name = "uploaded." + uploaded_file.name.split('.')[-1]
                        time1 = time.time()
                        msg = st.toast('å¼€å§‹ç”Ÿæˆ!')
                        msg.toast('æ­£åœ¨è¿›è¡Œè§†é¢‘æå–ğŸ“½ï¸')

                        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H-%M-%S")
                        output_file = cache_dir + current_time
                        os.makedirs(output_file)
                        with open(output_file + '/' + st.session_state.video_name, "wb") as file:
                            file.write(uploaded_file.getbuffer())
                        print(f"- æœ¬æ¬¡ä»»åŠ¡ç›®å½•ï¼š{output_file}")
                        file_to_mp3(log_setting, st.session_state.video_name, output_file)

                        time2 = time.time()
                        msg.toast('æ­£åœ¨è¯†åˆ«è§†é¢‘å†…å®¹ğŸ”')
                        if openai_whisper_api:
                            result = openai_whisper_result(openai_key, openai_base, output_file, whisper_prompt_setting, temperature_setting)
                        else:
                            device = 'cuda' if gpu_setting else 'cpu'
                            model = faster_whisper_model
                            if faster_whisper_local:
                                model = faster_whisper_local_path
                            result = faster_whisper_result(output_file, device, model, whisper_prompt_setting, temperature_setting, vad_setting, lang_setting, beam_size_setting, min_vad_setting)

                        time3 = time.time()
                        translation_dict = {
                            tuple([0]): 'æ— éœ€ç¿»è¯‘',
                            tuple([1]): 'æœ¬åœ°æ¨¡å‹',
                            tuple([2, 3]): 'gpt-3.5-turbo',
                            tuple([2, 4]): 'gpt-4o',
                            tuple([2, 5]): 'gpt-4',
                            tuple([6, 7]): 'moonshot-v1-8k',
                            tuple([6, 8]): 'moonshot-v1-32k',
                            tuple([6, 9]): 'moonshot-v1-128k',
                            tuple([10, 11]): 'glm-3-turbo',
                            tuple([10, 12]): 'glm-4v',
                            tuple([10, 13]): 'glm-4',
                            tuple([14, 15]): 'deepseek-chat'
                        }
                        translate_option = translation_dict[tuple(translate_setting)]

                        if translate_option != 'æ— éœ€ç¿»è¯‘':
                            print("***æ­£åœ¨æ‰§è¡Œç¿»è¯‘***\n")
                            msg.toast('æ­£åœ¨ç¿»è¯‘æ–‡æœ¬ğŸ¤–')
                            print("- ç¿»è¯‘æ¨¡å‹:" + translate_option)
                            if 'gpt' in translate_option:
                                result = translate(openai_key, openai_base, translate_option, result, language1_setting, language2_setting, wait_time_setting)
                            elif 'kimi' in translate_option:
                                result = translate(kimi_key, kimi_base, translate_option, result, language1_setting, language2_setting, wait_time_setting)
                            elif 'glm' in translate_option:
                                result = translate(chatglm_key, chatglm_base, translate_option, result, language1_setting, language2_setting, wait_time_setting)
                            elif 'deepseek' in translate_option:
                                result = translate(deepseek_key, deepseek_base, translate_option, result, language1_setting, language2_setting, wait_time_setting)
                            elif translate_option == 'æœ¬åœ°æ¨¡å‹':
                                result = local_translate(local_key, local_base, local_model, result, language1_setting, language2_setting)
                            print(" ")

                        time4 = time.time()
                        msg.toast('æ­£åœ¨ç”ŸæˆSRTå­—å¹•æ–‡ä»¶ğŸ“ƒ')
                        print("***æ­£åœ¨ç”ŸæˆSRTå­—å¹•æ–‡ä»¶***\n")
                        srt_content = generate_srt_from_result(result)
                        srt_content_style = generate_srt_from_result_2(result, font_setting, font_size_setting, font_color_setting)
                        with open(output_file + "/output.srt", 'w', encoding='utf-8') as srt_file:
                            srt_file.write(srt_content)
                        with open(output_file + "/output_with_style.srt", 'w', encoding='utf-8') as srt_file:
                            srt_file.write(srt_content_style)
                        st.session_state.output_file = output_file

                        time5 = time.time()
                        print("***å·²å®Œæˆ***\n")
                        st.toast("ä»»åŠ¡å·²å®Œæˆï¼", icon=":material/task_alt:")
                        total_time = time5 - time1
                        st.session_state.time = f"{total_time:.2f}"
                    else:
                        st.toast("æœªæ£€æµ‹åˆ°æ–‡ä»¶", icon=":material/error:")

                if st.button("åˆå¹¶å­—å¹•", type="primary", use_container_width=True, help="è¿›è¡Œå­—å¹•åˆå¹¶ï¼Œè‹¥å¯¹ä¸€é”®ç”Ÿæˆçš„ä¸æ»¡æ„ä¹Ÿå¯ä»¥é‡æ–°åˆå¹¶"):
                    try:
                        with open(st.session_state.output_file + "/output.srt", 'w', encoding='utf-8') as srt_file:
                            srt_file.write(st.session_state.srt_content_new)
                        with open(st.session_state.output_file + "/output_with_style.srt", 'w', encoding='utf-8') as srt_file:
                            srt_file.write(st.session_state.srt_data3)
                        test = st.session_state.video_name
                        time1 = time.time()
                        st.toast('æ­£åœ¨åˆå¹¶è§†é¢‘ï¼Œè¯·è€å¿ƒç­‰å¾…ç”Ÿæˆâš™ï¸')
                        print("***æ­£åœ¨åˆå¹¶è§†é¢‘***\n")
                        srt_mv(log_setting, st.session_state.video_name, crf_setting, quality_setting, ffmpeg_setting, st.session_state.output_file, font_setting, font_size_setting, font_color_setting, subtitle_model_setting)
                        print("***å·²å®Œæˆ***\n")
                        st.toast("ä»»åŠ¡å·²å®Œæˆï¼", icon=":material/task_alt:")
                        time2 = time.time()
                        total_time = time2 - time1
                        st.session_state.time = f"{total_time:.2f}"
                    except:
                        st.toast("æœªæ£€æµ‹åˆ°æ–‡ä»¶", icon=":material/error:")

                sac.divider(label='å…¶ä»–é¢„è§ˆè®¾ç½®', icon='arrow-down-square', align='center', color='gray')
                height = st.number_input("å­—å¹•è½´æ˜¾ç¤ºé«˜åº¦", min_value=400, step=100, value=400)
                st.session_state.height = height

                try:
                    captions_option = st.radio('æ›´å¤šå­—å¹•æ ¼å¼å¯¼å‡º', ('vtt', 'ass', 'stl'), index=0, horizontal=True)
                    if captions_option == 'vtt':
                        vtt_content = srt_to_vtt(st.session_state.srt_content_new)
                        st.download_button(
                            label="ä¸‹è½½VTTå­—å¹•",
                            data=vtt_content.encode('utf-8'),
                            key='vtt_download',
                            file_name='output.vvt',
                            mime='text/vtt',
                            use_container_width=True
                        )
                    elif captions_option == 'ass':
                        ass_content = srt_to_ass(st.session_state.srt_content_new, font_setting, font_size_setting, font_color_setting)
                        st.download_button(
                            label="ä¸‹è½½ASSå­—å¹•",
                            data=ass_content.encode('utf-8'),
                            key='ass_download',
                            file_name='output.ass',
                            mime='text/ass',
                            use_container_width=True
                        )
                    elif captions_option == 'stl':
                        stl_content = srt_to_stl(st.session_state.srt_content_new)
                        st.download_button(
                            label="ä¸‹è½½STLå­—å¹•",
                            data=stl_content.encode('utf-8'),
                            key='stl_download',
                            file_name='output.stl',
                            mime='text/stl',
                            use_container_width=True
                        )
                except:
                    if st.button('ä¸‹è½½å­—å¹•', use_container_width=True):
                        st.toast("æœªæ£€æµ‹åˆ°æ–‡ä»¶", icon=":material/error:")

                if st.button('æ‰“å¼€æ–‡ä»¶ç›®å½•', use_container_width=True):
                    try:
                        os.startfile(st.session_state.output_file)
                        st.toast("æ³¨æ„ï¼šæ–‡ä»¶å¤¹å·²æˆåŠŸæ‰“å¼€ï¼Œå¯èƒ½æœªç½®é¡¶æ˜¾ç¤ºï¼Œè¯·æ£€æŸ¥ä»»åŠ¡æ ï¼", icon=":material/task_alt:")
                    except:
                        st.toast("æœªæ£€æµ‹åˆ°æ–‡ä»¶", icon=":material/error:")

        with col1:
            with st.expander("srt_preview", expanded=True):
                try:
                    audio_file = open(st.session_state.output_file + "/output.mp3", 'rb')
                    audio_bytes = audio_file.read()
                    st.write("###### éŸ³è½¨")
                    st.audio(audio_bytes)
                except:
                    sac.alert(
                        label='**è¿è¡Œåè‡ªåŠ¨æ˜¾ç¤º**',
                        description='æœ‰é—®é¢˜å¯ä»¥æŸ¥é˜…æ–‡æ¡£[AAVT](https://zwho5v3j233.feishu.cn/wiki/OGcrwinzhi88MkkvEMVcLkDgnzc?from=from_copylink)ï¼Œæˆ–è€…åŠ ç¾¤è®¨è®ºå“¦',
                        size='lg', radius=20, icon=True, closable=True, color='info')

                try:
                    with open(st.session_state.output_file + "/output.srt", 'r', encoding='utf-8') as srt_file:
                        srt_content = srt_file.read()
                    srt_data1 = parse_srt_file(srt_content)
                    edited_data = st.data_editor(srt_data1, height=st.session_state.height, hide_index=True, use_container_width=True)
                    srt_data2 = convert_to_srt(edited_data)
                    st.session_state.srt_data3 = add_font_settings(srt_data2, font_color_setting, font_setting, font_size_setting)
                    st.session_state.srt_content_new = srt_data2
                except:
                    srt_data = [{"index": "", "start": "", "end": "", "content": ""}]
                    st.data_editor(srt_data, height=st.session_state.height, hide_index=True, use_container_width=True)

        try:
            sac.alert(
                label=f'æ€»è€—æ—¶ï¼š{st.session_state.time}s',
                size='lg', radius=20, icon=True, closable=True, color='success')
        except:
            test = 1
        sac.divider(label='POWERED BY @CHENYME', icon='lightning-charge', align='center', color='gray', key="2")

        with col5:
            try:
                st.write("**åŸå§‹çš„è§†é¢‘**")
                video_bytes = show_video(st.session_state.output_file, st.session_state.video_name)
                st.video(video_bytes)
            except:
                sac.alert(
                    label='**åŸå§‹è§†é¢‘é¢„è§ˆçª—å£**',
                    description='ä¸Šä¼ åè‡ªåŠ¨æ˜¾ç¤ºé¢„è§ˆç»“æœ',
                    size='lg', radius=20, icon=True, closable=True, color='info')
        with col6:
            try:
                st.write("**å¤„ç†åçš„è§†é¢‘**")
                video_bytes = show_video(st.session_state.output_file, "output.mp4")
                st.video(video_bytes)
            except:
                sac.alert(
                    label='**ç”Ÿæˆè§†é¢‘é¢„è§ˆçª—å£**',
                    description='è¿è¡Œåè‡ªåŠ¨æ˜¾ç¤ºé¢„è§ˆç»“æœ',
                    size='lg', radius=20, icon=True, closable=True, color='info')
