# ä½œè€…ï¼šchenyme
# ç‰ˆæœ¬ï¼šv0.3
# åšå®¢ç«™ï¼šå¾…æ›´æ–°

import os
import json
import streamlit as st
import torch
from openai import OpenAI
from utils.utils import (
    generate_srt_from_result,
    openai_translate1,
    openai_translate2,
    kimi_translate,
    srt_mv,
    cache,
    convert_size,
    whisper_choose,
    parse_srt_file,
    save_srt_file,
)

st.set_page_config(
    page_title="AAMT v0.3",
    page_icon="ğŸï¸",
    layout="wide",  # è®¾ç½®å¸ƒå±€æ ·å¼ä¸ºå®½å±•ç¤º
    initial_sidebar_state="expanded"  # è®¾ç½®åˆå§‹è¾¹æ çŠ¶æ€ä¸ºå±•å¼€
)

st.title("AIå…¨è‡ªåŠ¨è§†é¢‘ç¿»è¯‘ğŸï¸")


dir_1 = os.path.dirname(os.path.abspath(__file__))
dir_2 = dir_1.replace("\\", "/")
log_dir = dir_2 + "/public/log.md"
read_dir = dir_2 + "/public/README.md"  # Readmeæ–‡æ¡£
config_dir = dir_2 + "/config/"  # é…ç½®æ–‡ä»¶
cache_dir = dir_2 + "/cache/"  # æœ¬åœ°ç¼“å­˜
temp_dir = dir_2 + "/cache/"  # è¿è¡Œç¼“å­˜
print("å½“å‰é¡¹ç›®çš„é…ç½®æ–‡ä»¶ä½ç½®ï¼š", config_dir)
print("å½“å‰é¡¹ç›®çš„æœ¬åœ°ç¼“å­˜ä½ç½®ï¼š", cache_dir)
SRT = False

with st.sidebar:
    st.title("POWERD BY @CHENYME")
    st.caption("ğŸ–¥Chenyme-AAMT Versionï¼š0.3")
    st.write("------")
    st.write(
        "æ­å–œä½ å®Œæˆäº†AAMTé¡¹ç›®çš„éƒ¨ç½²ï¼è¯·å…ˆå‰å¾€è®¾ç½®é¡µé¢é…ç½®ç¯å¢ƒï¼ŒåŒæ—¶ç¡®ä¿æŒ‰ç…§æ­¥éª¤å®‰è£…å¥½æ‰€æœ‰ä¾èµ–ç¯å¢ƒå’Œåº“ï¼Œä»¥ä¿è¯é¡¹ç›®ç¨³å®šè¿è¡Œï¼")
    with open(read_dir, 'r', encoding='utf-8') as file:
        markdown_content = file.read()
    t = st.container(border=True, height=500)
    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": markdown_content}]
    t.caption("ğŸš€ A chatbot build with OpenAI LLM")
    for msg in st.session_state.messages:
        t.chat_message(msg["role"]).write("æ¬¢è¿æ¥åˆ°AAMT v0.3ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œæ‚¨å¯ä»¥éšæ—¶å‘æˆ‘å‘èµ·æé—®ï¼")

    if prompt := st.text_input("è¾“å…¥æ‚¨çš„é—®é¢˜", help="è¿™æ˜¯åŸºäºGPT3.5çš„AIåŠ©æ‰‹ï¼Œä½ å¯ä»¥é—®ä»»ä½•é—®é¢˜ï¼ŒæŒ‰Enterä»¥å‘é€"):
        client = OpenAI(api_key=st.session_state.openai_key, base_url=st.session_state.openai_base)
        st.session_state.messages.append({"role": "user", "content": prompt})
        t.chat_message("user").write(prompt)
        response = client.chat.completions.create(model="gpt-3.5-turbo", messages=st.session_state.messages)
        msg = response.choices[0].message.content
        st.session_state.messages.append({"role": "assistant", "content": msg})
        t.chat_message("assistant").write(msg)

with open(config_dir + "config.json", 'r') as file:  # è¯»å–é…ç½®
    config = json.load(file)

tab1, tab2, tab3 = st.tabs(["ä¸»é¡µ", "è®¾ç½®", "å…³äº"])

with tab1:
    col1, col2 = st.columns(2, gap="medium")
    with col1:
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader("è¯·åœ¨è¿™é‡Œä¸Šä¼ è§†é¢‘ï¼š", type=['mp4', 'mov'])
        if uploaded_file is not None:
            with open(cache_dir + "uploaded.mp4", "wb") as file:
                file.write(uploaded_file.getbuffer())
            st.success("ä¸Šä¼ æˆåŠŸ")

        # é€‰æ‹©ç¿»è¯‘æ¨¡å‹
        option = st.selectbox('é€‰æ‹©ä½ è¦ä½¿ç”¨çš„ç¿»è¯‘æ¨¡å‹', ('kimi', 'gpt-3.5-turbo', 'gpt-4', 'æ— éœ€ç¿»è¯‘'), index=0)

        # ç¿»è¯‘è¯­ç§è®¾ç½®
        if option != 'æ— éœ€ç¿»è¯‘':
            language1 = st.selectbox('åŸå§‹è¯­è¨€', ('ä¸­æ–‡', 'English', 'æ—¥æœ¬èª', 'í•œêµ­ì¸', 'Italiano', 'Deutsch'), index=1)
            language2 = st.selectbox('ç›®æ ‡è¯­è¨€', ('ä¸­æ–‡', 'English', 'æ—¥æœ¬èª', 'í•œêµ­ì¸', 'Italiano', 'Deutsch'), index=0)

        # GPUåŠ é€Ÿ
        wdc = not torch.cuda.is_available()
        on = st.toggle('å¯ç”¨GPUåŠ é€Ÿ*', disabled=wdc, help='è¯·ç¡®ä¿æ‚¨æ­£ç¡®å®‰è£…äº†cudaã€pytorchï¼Œå¦åˆ™è¯¥é€‰é¡¹å¼€å¯æ— æ•ˆï¼')
        device = 'cuda' if on else 'cpu'

        if option != 'æ— éœ€ç¿»è¯‘':
            with col2:
                c = st.container(border=True, height=500)
                c.write('é¢„è§ˆï¼ˆPreviewï¼‰')
            if st.button('è¿è¡Œç¨‹åº'):
                with col2:
                    if uploaded_file is not None:
                        with st.spinner('æ­£åœ¨è¯†åˆ«è§†é¢‘å†…å®¹...'):
                            # whisperè¯†åˆ«
                            result, path_video = whisper_choose(uploaded_file, temp_dir,
                                                                st.session_state.w_model_option,
                                                                device,
                                                                st.session_state.w_name)
                            os.unlink(path_video)  # åˆ é™¤ç¼“å­˜æ–‡ä»¶
                            print("whisperè¯†åˆ«ï¼š" + result['text'])  # whisperæºè¯­è¨€è¯†åˆ«å†…å®¹

                        with st.spinner('æ­£åœ¨ç¿»è¯‘æ–‡æœ¬...'):
                            if option == 'kimi':
                                result = kimi_translate(st.session_state.kimi_key, result, language1,
                                                        language2)  # ä½¿ç”¨kimiç¿»è¯‘æˆç›®æ ‡è¯­è¨€
                            elif option == 'gpt-3.5-turbo':
                                result = openai_translate1(st.session_state.openai_key, st.session_state.openai_base,
                                                           result,
                                                           language1, language2)  # ä½¿ç”¨gpt3.5ç¿»è¯‘æˆç›®æ ‡è¯­è¨€
                            elif option == 'gpt-4':
                                result = openai_translate2(st.session_state.openai_key, st.session_state.openai_base,
                                                           result,
                                                           language1, language2)  # ä½¿ç”¨gpt4ç¿»è¯‘æˆç›®æ ‡è¯­è¨€

                        with st.spinner('æ­£åœ¨ç”ŸæˆSRTå­—å¹•æ–‡ä»¶...'):
                            srt_content = generate_srt_from_result(result)  # ç”ŸæˆSRTå­—å¹•å†…å®¹
                            with open(cache_dir + "output.srt", 'w', encoding='utf-8') as srt_file:  # å°†SRTå†…å®¹å†™å…¥SRTæ–‡ä»¶
                                srt_file.write(srt_content)
                            SRT = True

                        with st.spinner('æ­£åœ¨åˆå¹¶è§†é¢‘ï¼Œè¯·è€å¿ƒç­‰å¾…è§†é¢‘ç”Ÿæˆ...'):
                            srt_mv(cache_dir)
                        c.success("ç¿»è¯‘å·²å®Œæˆï¼")

                        video_file = open(cache_dir + "output.mp4", 'rb')
                        video_bytes = video_file.read()
                        c.video(video_bytes)

                    else:
                        with col1:
                            st.error("è¯·å…ˆä¸Šä¼ è§†é¢‘ï¼")

        elif option == 'æ— éœ€ç¿»è¯‘':
            with col2:
                c = st.container(border=True, height=500)
                c.write('é¢„è§ˆï¼ˆPreviewï¼‰')

            if st.button('è¿è¡Œç¨‹åº'):
                with col2:
                    if uploaded_file is not None:
                        with st.spinner('æ­£åœ¨è¯†åˆ«è§†é¢‘å†…å®¹...'):
                            # whisperè¯†åˆ«
                            result, path_video = whisper_choose(uploaded_file, temp_dir,
                                                                st.session_state.w_model_option,
                                                                device,
                                                                st.session_state.w_name)
                            os.unlink(path_video)  # åˆ é™¤ç¼“å­˜æ–‡ä»¶

                        with st.spinner('æ­£åœ¨ç”ŸæˆSRTå­—å¹•æ–‡ä»¶...'):
                            srt_content = generate_srt_from_result(result)  # ç”ŸæˆSRTå­—å¹•å†…å®¹
                            with open(cache_dir + "output.srt", 'w', encoding='utf-8') as srt_file:  # å°†SRTå†…å®¹å†™å…¥SRTæ–‡ä»¶
                                srt_file.write(srt_content)
                            SRT = True

                        with st.spinner('æ­£åœ¨åˆå¹¶è§†é¢‘ï¼Œè¯·è€å¿ƒç­‰å¾…è§†é¢‘ç”Ÿæˆ...'):
                            srt_mv(cache_dir)
                        c.success("ç¿»è¯‘å·²å®Œæˆï¼")

                        video_file = open(cache_dir + "output.mp4", 'rb')
                        video_bytes = video_file.read()
                        c.video(video_bytes)

                    else:
                        with col1:
                            st.error("è¯·å…ˆä¸Šä¼ è§†é¢‘ï¼")

st.write('''------
##### å®éªŒåŠŸèƒ½ğŸ§ª''')
st.caption("è¿è¡Œç¨‹åºåè‡ªåŠ¨æ˜¾ç¤ºï¼Œå®é™…å¯èƒ½ä¼šæœ‰BUGï¼Œåç»­ç‰ˆæœ¬ä¼šé€æ­¥å®Œå–„å¹¶å®è£…ï¼")
file_path = cache_dir + 'output.srt'
if SRT:
    srt_data = parse_srt_file(file_path)
    edited_data = st.data_editor(srt_data, height=300, hide_index=True)

    if edited_data is not None:
        st.write('ç¼–è¾‘åçš„æ•°æ®ï¼š')
        st.write(edited_data)

    with open(cache_dir + 'output.srt', "rb") as file:
        contents = file.read()

    if st.button('ä¿å­˜ä¿®æ”¹åçš„SRT'):
        save_srt_file(edited_data, file_path)
        st.write('æ•°æ®å·²ä¿å­˜è‡³', file_path)


# å…¨å±€è®¾ç½®
with tab2:
    openai_api_key = config["openai_key"]
    openai_api_base = config["openai_base"]
    kimi_api_key = config["kimi_key"]
    whisper_version = config["whisper_version_default"]
    whisper_model = config["whisper_model_default"]

    # Whisperæ¨¡å‹
    st.write("#### Whisperè¯†åˆ«è®¾ç½®")
    w_version_d = {'openai-whisper': 0, 'faster-whisper': 1}
    w_model_d = {'tiny': 0, 'base': 1, 'small': 2, 'medium': 3, 'large': 4}

    w_version = st.selectbox('é€‰æ‹©whisperç‰ˆæœ¬', ('openai-whisper', 'faster-whisper'),
                             index=w_version_d[whisper_version])
    w_model_option = st.selectbox('é€‰æ‹©è¯†åˆ«æ¨¡å‹', ('tiny', 'base', 'small', 'medium', 'large'),
                                  index=w_model_d[whisper_model])

    if w_model_option != whisper_model:
        config["whisper_model_default"] = w_model_option
        with open(config_dir + "config.json", 'w') as file:
            json.dump(config, file, indent=4)
        st.success("é»˜è®¤æ¨¡å‹å·²åˆ‡æ¢ä¸ºï¼š" + w_model_option)

    if w_version != whisper_version:
        config["whisper_version_default"] = w_version
        with open(config_dir + "config.json", 'w') as file:
            json.dump(config, file, indent=4)
        st.success("é»˜è®¤ç‰ˆæœ¬å·²åˆ‡æ¢ä¸ºï¼š" + w_version)

    st.write('------')
    # OPENAIè´¦æˆ·
    st.write("#### ç¿»è¯‘è®¾ç½®")
    st.write("###### KIMIè´¦æˆ·è®¾ç½®")
    new_kimi_key = st.text_input("KIMI-API-KEYï¼š")
    st.write("###### OPENAIè´¦æˆ·è®¾ç½®")
    new_openai_base = st.text_input("OPENAI-API-BASEï¼š")
    new_openai_key = st.text_input("OPENAI-API-KEYï¼š")

    if st.button("ä¿å­˜"):
        if new_kimi_key != kimi_api_key and new_kimi_key != "":
            config["kimi_key"] = new_kimi_key
            kimi_api_key = new_kimi_key
        if new_openai_base != openai_api_base and new_openai_base != "":
            config["openai_key"] = new_openai_key
            openai_api_key = new_openai_key
        if new_openai_key != openai_api_key and new_openai_key != "":
            config["openai_base"] = new_openai_base
            openai_api_base = new_openai_base
        with open(config_dir + "config.json", 'w') as file:
            json.dump(config, file, indent=4)
        st.success("å·²ä¿å­˜")

    st.write('------')
    # æœ¬åœ°ç¼“å­˜
    st.write("#### æœ¬åœ°ç¼“å­˜")
    st.write(f"æœ¬åœ°ç¼“å­˜å·²å ç”¨ï¼š{convert_size(cache(cache_dir))}")
    if st.button("æ¸…é™¤æœ¬åœ°ç¼“å­˜"):
        # è·å–æ–‡ä»¶å¤¹å†…æ‰€æœ‰æ–‡ä»¶çš„åˆ—è¡¨
        file_list = os.listdir(cache_dir)
        # éå†åˆ—è¡¨ä¸­çš„æ–‡ä»¶ï¼Œå¹¶åˆ é™¤æ¯ä¸ªæ–‡ä»¶
        for file_name in file_list:
            file_path = os.path.join(cache_dir, file_name)
            if os.path.isfile(file_path):
                os.remove(file_path)
        st.success("æ‰€æœ‰ç¼“å­˜æ–‡ä»¶å·²æˆåŠŸåˆ é™¤ã€‚")

    st.session_state.openai_base = openai_api_base
    st.session_state.openai_key = openai_api_key
    st.session_state.kimi_key = kimi_api_key
    st.session_state.w_model_option = w_model_option
    st.session_state.w_name = w_version

with tab3:
    with open(log_dir, 'r', encoding='utf-8') as file:
        markdown_log = file.read()
    st.write(markdown_log)
    st.caption('ç”±æœ¬åœ°log.mdè¯»å–åŠ è½½')
    st.write(markdown_content)
    st.caption('ç”±æœ¬åœ°README.mdè¯»å–åŠ è½½')
