import os
import toml
import time
import torch
import datetime
import streamlit as st
import streamlit_antd_components as sac
from utils.utils import (get_whisper_result, kimi_translate, openai_translate1, openai_translate2, chatglm_translate,
                         local_translate, generate_srt_from_result, srt_mv, srt_to_vtt, srt_to_ass, srt_to_stl, show_video,
                         parse_srt_file, convert_to_srt, generate_srt_from_result_2, deepseek_translate, openai_whisper)


def video():
    project_dir = os.path.dirname(os.path.abspath(__file__)).replace("\\", "/")
    cache_dir = project_dir + "/cache/"  # æœ¬åœ°ç¼“å­˜
    config_dir = project_dir.replace("/project", "") + "/config/"  # é…ç½®æ–‡ä»¶

    # åŠ è½½é…ç½®
    config = toml.load(config_dir + "config.toml")
    openai_api_key = config["GPT"]["openai_key"]
    openai_api_base = config["GPT"]["openai_base"]
    kimi_api_key = config["KIMI"]["kimi_key"]
    deepseek_api_key = config["DEEPSEEK"]["deepseek_key"]
    chatglm_api_key = config["CHATGLM"]["chatglm_key"]
    faster_whisper_model = config["WHISPER"]["faster_whisper_model_default"]
    faster_whisper_model_local = config["WHISPER"]["faster_whisper_model_local"]
    faster_whisper_model_path = config["WHISPER"]["faster_whisper_model_local_path"]
    openai_whisper_api = config["WHISPER"]["openai_whisper_api"]

    # é¡µé¢ç¼“å­˜
    st.session_state.openai_base = openai_api_base
    st.session_state.openai_key = openai_api_key
    st.session_state.kimi_key = kimi_api_key
    st.session_state.deepseek_key = deepseek_api_key
    st.session_state.chatglm_key = chatglm_api_key
    st.session_state.model_local = faster_whisper_model_local
    st.session_state.model_path = faster_whisper_model_path
    st.session_state.faster_whisper_model = faster_whisper_model
    st.session_state.openai_whisper_api = openai_whisper_api

    # å¯ç”¨è®¾ç½®
    opt_g = 1
    if "distil" not in faster_whisper_model or torch.cuda.is_available():
        opt_g = 0

    # ä¸»é¡µé¢
    st.title("AIå…¨è‡ªåŠ¨è§†é¢‘ç¿»è¯‘ğŸ“½ï¸")
    st.write("")

    with st.sidebar:
        st.write("### æ–‡ä»¶ä¸Šä¼ å™¨")
        uploaded_file = st.file_uploader("è¯·åœ¨è¿™é‡Œä¸Šä¼ è§†é¢‘ï¼š", type=['mp4', 'mov'], label_visibility="collapsed")

    col1, col2 = st.columns(2, gap="medium")
    with col1:
        if not openai_whisper_api:
            with st.expander("**è¯†åˆ«è®¾ç½®**", expanded=True):
                col3, col4 = st.columns(2)
                with col3:
                    GPU_on = st.toggle('å¯ç”¨GPUåŠ é€Ÿ', disabled=opt_g, help='è‡ªåŠ¨æ£€æµ‹cudaã€pytorchå¯ç”¨åå¼€å¯ï¼')  # GPU
                    VAD_on = st.toggle('å¯ç”¨VADè¾…åŠ©',
                                       help='å¯ç”¨è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVADï¼‰ä»¥è¿‡æ»¤æ‰æ²¡æœ‰è¯­éŸ³çš„éŸ³é¢‘éƒ¨åˆ†,ä»…æ”¯æŒfaster-whisperä½¿ç”¨ã€‚')  # VAD
                    device = 'cuda' if GPU_on else 'cpu'
                    vad = 'True' if VAD_on else 'False'
                with col4:
                    language = ('è‡ªåŠ¨è¯†åˆ«', 'zh', 'en', 'ja', 'ko', 'it', 'de')  # language
                    lang = st.selectbox('é€‰æ‹©è§†é¢‘è¯­è¨€', language, index=0,
                                        help="å¼ºåˆ¶æŒ‡å®šè§†é¢‘è¯­è¨€ä¼šæé«˜è¯†åˆ«å‡†ç¡®åº¦ï¼Œä½†ä¹Ÿå¯èƒ½ä¼šé€ æˆè¯†åˆ«å‡ºé”™ã€‚")
        else:
            with st.expander("**APIè°ƒç”¨æ¨¡å¼**", expanded=True):
                proxy_on = st.toggle('å¯ç”¨ä»£ç†', help='å¦‚æœä½ èƒ½ç›´æ¥è®¿é—®openai.comï¼Œåˆ™æ— éœ€å¯ç”¨ã€‚')

        with st.expander("**ç¿»è¯‘è®¾ç½®**", expanded=True):
            translate_option = sac.cascader(items=[
                sac.CasItem('æ— éœ€ç¿»è¯‘'),
                sac.CasItem('æœ¬åœ°æ¨¡å‹', icon='house-up-fill'),
                sac.CasItem('ChatGPT-OpenAI', icon='node-plus-fill', children=[
                    sac.CasItem('gpt-3.5-turbo', icon='robot'),
                    sac.CasItem('gpt-4o', icon='robot'),
                    sac.CasItem('gpt-4', icon='robot')]),
                sac.CasItem('Moonshot-æœˆä¹‹æš—é¢', icon='node-plus-fill', children=[
                    sac.CasItem('kimi-moonshot-v1-8k', icon='robot'),
                    sac.CasItem('kimi-moonshot-v1-32k', icon='robot'),
                    sac.CasItem('kimi-moonshot-v1-128k', icon='robot')]),
                sac.CasItem('ChatGLM-æ™ºè°±AI', icon='node-plus-fill', children=[
                    sac.CasItem('glm-3-turbo', icon='robot'),
                    sac.CasItem('glm-4v', icon='robot'),
                    sac.CasItem('glm-4', icon='robot')]),
                sac.CasItem('DeepSeek-æ·±åº¦æ±‚ç´¢', icon='node-plus-fill', children=[
                    sac.CasItem('deepseek-v2', icon='robot')]),
            ], label='ç¿»è¯‘å¼•æ“', search=True, index=0)
            translate_option = translate_option[-1]

            if translate_option == 'æœ¬åœ°æ¨¡å‹':
                col3, col4, col5 = st.columns(3)
                with col3:
                    base_url = st.text_input('æ¨¡å‹æ¥å£', help='æ ·ä¾‹: http://127.0.0.1:8888/', value='http://xxx')
                with col4:
                    api_key = st.text_input('æ¨¡å‹å¯†é’¥', help='è‹¥æ— éœ€keyï¼Œè¯·ç•™ç©º', value='')
                with col5:
                    model_name = st.text_input('æ¨¡å‹è°ƒç”¨åç§°', help='æ ·ä¾‹: chatglm3-6B', value='xxx')

            elif 'è¯‘' not in translate_option:
                language = ('ä¸­æ–‡', 'English', 'æ—¥æœ¬èª', 'í•œêµ­ì¸', 'Italiano', 'Deutsch')
                col3, col4, col5 = st.columns(3)
                with col3:
                    language1 = st.selectbox('é€‰æ‹©åŸå§‹è¯­è¨€', language, index=1)
                with col4:
                    language2 = st.selectbox('é€‰æ‹©ç›®æ ‡è¯­è¨€', language, index=0)
                with col5:
                    waittime = st.number_input('ç¿»è¯‘é—´éš”è®¾ç½®', min_value=0.0, max_value=5.0, value=0.1, step=0.1)
            else:
                a = None
            if 'gpt' in translate_option and not openai_whisper_api:
                proxy_on = st.toggle('å¯ç”¨ä»£ç†', help='å¦‚æœä½ èƒ½ç›´æ¥è®¿é—®openai.comï¼Œåˆ™æ— éœ€å¯ç”¨ã€‚')

        with st.expander("**å­—å¹•è®¾ç½®**", expanded=True):
            with open(project_dir.replace("/project", "/config") + '/font_data.txt', 'r', encoding='utf-8') as file:
                lines = file.readlines()
                fonts = [line.strip() for line in lines]
                col3, col4 = st.columns(2, gap="medium")
                with col3:
                    subtitle_model = st.selectbox('å­—å¹•æ–¹å¼ï¼š', ("ç¡¬å­—å¹•", "è½¯å­—å¹•"),
                                                  help="è¯·æ³¨æ„ï¼šç”±äºè½¯å­—å¹•ä¼šå¯¼è‡´éƒ¨åˆ†å­—ä½“ä¼šæ— æ³•æ­£å¸¸æ˜¾ç¤ºï¼Œå› æ­¤å¯èƒ½ä¼šå‡ºç°ä¹±ç ï¼åŒæ—¶ï¼Œæ‚¨æ— æ³•åœ¨ç½‘é¡µä¸­é¢„è§ˆå­—å¹•æ•ˆæœï¼Œè¯·æ‰“å¼€æ–‡ä»¶å¤¹è®¿é—®åŸè§†é¢‘å¹¶ä½¿ç”¨æ”¯æŒå¤–æŒ‚å­—å¹•çš„è§†é¢‘æ’­æ”¾å™¨æŒ‚è½½å­—å¹•æŸ¥çœ‹æ•ˆæœï¼")
                with col4:
                    font = st.selectbox('è§†é¢‘å­—å¹•å­—ä½“ï¼š', fonts,
                                        help="æ‰€æœ‰å­—ä½“å‡ä»ç³»ç»Ÿè¯»å–åŠ è½½ï¼Œæ”¯æŒç”¨æˆ·è‡ªè¡Œå®‰è£…å­—ä½“ã€‚è¯·æ³¨æ„å•†ç”¨é£é™©ï¼")
                    st.session_state.font = font
                col3, col4 = st.columns([0.9, 0.1], gap="medium")
                with col3:
                    font_size = st.number_input('å­—å¹•å­—ä½“å¤§å°', min_value=1, max_value=30, value=18, step=1,
                                                help="æ¨èå¤§å°ï¼š18")
                    st.session_state.font_size = font_size
                with col4:
                    font_color = st.color_picker('é¢œè‰²', '#FFFFFF')
                    st.session_state.font_color = font_color
    with col2:
        with st.expander("**é«˜çº§è®¾ç½®**"):
            if not openai_whisper_api:
                min_vad = st.number_input('VADé™éŸ³æ£€æµ‹(ms)', min_value=100, max_value=5000, value=500, step=100,
                                          help="å¯ç”¨VADè¾…åŠ©åç”Ÿæ•ˆï¼å¯¹åº”`min_silence_duration_ms`å‚æ•°ï¼Œæœ€å°é™éŸ³æŒç»­æ—¶é—´ã€‚")
                beam_size = st.number_input('æŸæœç´¢å¤§å°', min_value=1, max_value=20, value=5, step=1,
                                            help="`beam_size`å‚æ•°ã€‚ç”¨äºå®šä¹‰æŸæœç´¢ç®—æ³•ä¸­æ¯ä¸ªæ—¶é—´æ­¥ä¿ç•™çš„å€™é€‰é¡¹æ•°é‡ã€‚æŸæœç´¢ç®—æ³•é€šè¿‡åœ¨æ¯ä¸ªæ—¶é—´æ­¥é€‰æ‹©æœ€æœ‰å¯èƒ½çš„å€™é€‰é¡¹æ¥æ„å»ºæœç´¢æ ‘ï¼Œå¹¶æ ¹æ®å€™é€‰é¡¹çš„å¾—åˆ†è¿›è¡Œæ’åºå’Œå‰ªæã€‚è¾ƒå¤§çš„beam_sizeå€¼ä¼šä¿ç•™æ›´å¤šçš„å€™é€‰é¡¹ï¼Œæ‰©å¤§æœç´¢ç©ºé—´ï¼Œå¯èƒ½æé«˜ç”Ÿæˆç»“æœçš„å‡†ç¡®æ€§ï¼Œä½†ä¹Ÿä¼šå¢åŠ è®¡ç®—å¼€é”€ã€‚ç›¸åï¼Œè¾ƒå°çš„beam_sizeå€¼ä¼šå‡å°‘è®¡ç®—å¼€é”€ï¼Œä½†å¯èƒ½å¯¼è‡´æœç´¢è¿‡æ—©åœ°æ”¾å¼ƒæœ€ä½³åºåˆ—ã€‚")
            else:
                whisper_prompt = st.text_input('Whisperæç¤ºè¯', value='Donâ€™t make each line too long.')
                temperature = st.number_input('Whisperæ¸©åº¦', min_value=0.0, max_value=1.0, value=0.8, step=0.1)
            token_num = st.number_input('ç¿»è¯‘æœ€å¤§tokené™åˆ¶', min_value=10, max_value=500, value=100, step=10,
                                        help="æœ€å¤§tokené‡ä¸ºï¼š500*ç¿»è¯‘æœ€å¤§tokené™åˆ¶")
    with col1:
        if st.button("è¿è¡Œç¨‹åº", use_container_width=True, type="primary"):
            if uploaded_file is not None:
                msg = st.toast('å¼€å§‹ç”Ÿæˆ!')
                time1 = time.time()
                msg.toast('æ­£åœ¨è¿›è¡Œè§†é¢‘è¯»å–ğŸ“½ï¸')
                current_time = datetime.datetime.now().strftime("%Y-%m-%d %H-%M-%S")
                output_file = cache_dir + current_time
                print(output_file)
                os.makedirs(output_file)
                with open(output_file + "/uploaded.mp4", "wb") as file:
                    file.write(uploaded_file.getbuffer())

                time2 = time.time()
                msg.toast('æ­£åœ¨è¯†åˆ«è§†é¢‘å†…å®¹ğŸ”')
                if openai_whisper_api:
                    print("---\nAPIè°ƒç”¨æ¨¡å¼")
                    result = openai_whisper(st.session_state.openai_key, st.session_state.openai_base, proxy_on,
                                            whisper_prompt, temperature, output_file)
                    print("---\nwhisperè¯†åˆ«å†…å®¹ï¼š" + result['text'])
                else:
                    models_option = st.session_state.faster_whisper_model
                    if st.session_state.model_local:
                        models_option = st.session_state.model_path
                    print("---\næœ¬åœ°è°ƒç”¨æ¨¡å¼\nåŠ è½½æ¨¡å‹ï¼š" + models_option)
                    result = get_whisper_result(uploaded_file, output_file, device, models_option, vad, lang, beam_size,
                                                min_vad)
                    print("---\nwhisperè¯†åˆ«å†…å®¹ï¼š" + result['text'])

                time3 = time.time()
                if translate_option != 'è¯‘':
                    msg.toast('æ­£åœ¨ç¿»è¯‘æ–‡æœ¬ğŸ¤–')
                    print("---\nç¿»è¯‘æ¨¡å‹:" + translate_option)
                    if translate_option == 'gpt-3.5-turbo' or translate_option == 'gpt-4o':
                        result = openai_translate1(st.session_state.openai_key, st.session_state.openai_base,
                                                   proxy_on, result, language1, language2, waittime)
                    elif translate_option == 'gpt-4':
                        result = openai_translate2(st.session_state.openai_key, st.session_state.openai_base,
                                                   proxy_on, result, language1, language2, token_num, waittime)
                    elif translate_option == 'deepseek-v2':
                        result = deepseek_translate(st.session_state.deepseek_key, result, language2, waittime)
                    elif 'glm' in translate_option:
                        result = chatglm_translate(st.session_state.chatglm_key, translate_option, result, language2,
                                                   waittime)
                    elif 'kimi' in translate_option:
                        result = kimi_translate(st.session_state.kimi_key, translate_option, result, language1,
                                                language2, token_num, waittime)
                    elif translate_option == 'æœ¬åœ°æ¨¡å‹':
                        result = local_translate(base_url, api_key, model_name, result, language2)

                time4 = time.time()
                msg.toast('æ­£åœ¨ç”ŸæˆSRTå­—å¹•æ–‡ä»¶ğŸ“ƒ')
                srt_content = generate_srt_from_result(result)
                srt_content2 = generate_srt_from_result_2(result, font, font_size, font_color)
                with open(output_file + "/output.srt", 'w', encoding='utf-8') as srt_file:
                    srt_file.write(srt_content2)

                time5 = time.time()
                msg.toast('æ­£åœ¨åˆå¹¶è§†é¢‘ï¼Œè¯·è€å¿ƒç­‰å¾…ç”Ÿæˆâš™ï¸')
                srt_mv(output_file, font, font_size, font_color, subtitle_model)

                time6 = time.time()
                st.toast("ğŸ‰ğŸ‰ğŸ‰")
                st.session_state.srt_content = srt_content
                st.session_state.output = output_file
                st.session_state.current = current_time
                st.session_state.time = time6 - time1
                formatted_result = f"{st.session_state.time:.2f}"
                msg.toast('è¿è¡ŒæˆåŠŸï¼æ€»ç”¨æ—¶ï¼š' + str(formatted_result) + "ç§’")
            else:
                st.toast("è¯·å…ˆä¸Šä¼ è§†é¢‘")

    with col2:
        with st.expander("**è§†é¢‘é¢„è§ˆ**", expanded=True):
            try:
                video_bytes = show_video(st.session_state.output)
                st.video(video_bytes)

                if sac.buttons([sac.ButtonsItem(label='æŸ¥çœ‹æ–‡ä»¶ç›®å½•', icon='calendar2-minus-fill')], index=None, align='center', variant='filled', use_container_width=True):
                    os.startfile(st.session_state.output)
                    st.toast("æ³¨æ„ï¼šæ–‡ä»¶å¤¹å·²æˆåŠŸæ‰“å¼€ï¼Œå¯èƒ½æœªç½®é¡¶æ˜¾ç¤ºï¼Œè¯·æ£€æŸ¥ä»»åŠ¡æ ï¼")
            except:
                with st.container(height=300):
                    st.write("")
                st.success('''
                    **è¿™é‡Œæ˜¯è§†é¢‘é¢„è§ˆçª—å£**                             
                    **è¿è¡Œåè‡ªåŠ¨æ˜¾ç¤ºé¢„è§ˆç»“æœ**
                ''')

    st.write('''------''')
    st.write('**å­—å¹•æ—¶é—´è½´**(è¿è¡Œåè‡ªåŠ¨æ˜¾ç¤º)')
    try:
        srt_data1 = parse_srt_file(st.session_state.srt_content)
        edited_data = st.data_editor(srt_data1, height=300, hide_index=True, use_container_width=True)
        srt_data2 = convert_to_srt(edited_data)
        st.session_state.srt_content_new = srt_data2
    except:
        srt_data = [{"index": "", "start": "", "end": "", "content": ""}]
        edited_data = st.data_editor(srt_data, height=300, hide_index=True, use_container_width=True)
    st.write('''
    ------
    ##### å®éªŒåŠŸèƒ½ğŸ§ª
    ''')
    st.caption("è¿è¡Œç¨‹åºåè‡ªåŠ¨æ˜¾ç¤ºï¼Œå®é™…å¯èƒ½ä¼šæœ‰BUGï¼Œåç»­ç‰ˆæœ¬ä¼šé€æ­¥å®Œå–„å¹¶å®è£…ï¼")

    col1, col2 = st.columns(2, gap="medium")
    with col1:
        with st.expander("**æ›´å¤šå­—å¹•æ ¼å¼**", expanded=True):
            try:
                captions_option = st.radio('å­—å¹•å¯¼å‡ºæ ¼å¼ï¼š', ('srt', 'vtt', 'ass', 'stl'), index=0, horizontal=True)
                if captions_option == 'srt':
                    st.download_button(
                        label="ç‚¹å‡»ä¸‹è½½SRTå­—å¹•æ–‡ä»¶",
                        data=st.session_state.srt_content_new.encode('utf-8'),
                        key='srt_download',
                        file_name='output.srt',
                        mime='text/srt',
                        type="primary",
                        use_container_width=True
                    )
                elif captions_option == 'vtt':
                    vtt_content = srt_to_vtt(st.session_state.srt_content_new)
                    st.download_button(
                        label="ç‚¹å‡»ä¸‹è½½VTTå­—å¹•æ–‡ä»¶",
                        data=vtt_content.encode('utf-8'),
                        key='vtt_download',
                        file_name='output.vvt',
                        mime='text/vtt',
                        type="primary",
                        use_container_width=True
                    )
                elif captions_option == 'ass':
                    print(st.session_state.font)
                    print(st.session_state.font_size)
                    print(st.session_state.font_color)
                    ass_content = srt_to_ass(st.session_state.srt_content_new, st.session_state.font,
                                             st.session_state.font_size, st.session_state.font_color)
                    print(1)
                    st.download_button(
                        label="ç‚¹å‡»ä¸‹è½½ASSå­—å¹•æ–‡ä»¶",
                        data=ass_content.encode('utf-8'),
                        key='ass_download',
                        file_name='output.ass',
                        mime='text/ass',
                        type="primary",
                        use_container_width=True
                    )
                elif captions_option == 'stl':
                    stl_content = srt_to_stl(st.session_state.srt_content_new)
                    st.download_button(
                        label="ç‚¹å‡»ä¸‹è½½STLå­—å¹•æ–‡ä»¶",
                        data=stl_content.encode('utf-8'),
                        key='stl_download',
                        file_name='output.stl',
                        mime='text/stl',
                        type="primary",
                        use_container_width=True
                    )
            except:
                st.warning('è¿™é‡Œæ˜¯å­—å¹•çª—å£ï¼Œè¿è¡Œåè‡ªåŠ¨æ˜¾ç¤ºä¸‹è½½æŒ‰é’®ã€‚')

        with st.expander("**é‡æ–°åˆæˆ**", expanded=True):
            with open(project_dir.replace("/project", "/config") + '/font_data.txt', 'r', encoding='utf-8') as file:
                lines = file.readlines()
                fonts = [line.strip() for line in lines]
                font = st.selectbox('å­—å¹•å­—ä½“ï¼š', fonts,
                                    help="æ‰€æœ‰å­—ä½“å‡ä»ç³»ç»Ÿè¯»å–åŠ è½½ï¼Œæ”¯æŒç”¨æˆ·è‡ªè¡Œå®‰è£…å­—ä½“ã€‚è¯·æ³¨æ„å•†ç”¨é£é™©ï¼")
                col3, col4 = st.columns([0.9, 0.1], gap="medium")
                with col3:
                    font_size = st.number_input('å­—ä½“å¤§å°', min_value=1, max_value=30, value=18, step=1,
                                                help="æ¨èå¤§å°ï¼š18")
                with col4:
                    font_color = st.color_picker('å­—ä½“é¢œè‰²', '#FFFFFF')

            if st.button("é‡æ–°åˆæˆ", use_container_width=True, type="primary"):
                st.session_state.output2 = cache_dir + st.session_state.current
                with open(st.session_state.output2 + "/output.srt", 'w', encoding='utf-8') as srt_file:
                    srt_file.write(st.session_state.srt_content_new)

                with st.spinner('æ­£åœ¨åˆå¹¶è§†é¢‘ï¼Œè¯·è€å¿ƒç­‰å¾…è§†é¢‘ç”Ÿæˆ...'):
                    srt_mv(st.session_state.output2, font, font_size, font_color, subtitle_model)

    with col2:
        with st.expander("**ä¿®æ”¹åçš„è§†é¢‘é¢„è§ˆ**", expanded=True):
            try:
                print(st.session_state.output2)
                video_bytes = show_video(st.session_state.output2)
                st.video(video_bytes)
                print(1)
                if st.button('æŸ¥çœ‹æ–‡ä»¶', use_container_width=True):
                    os.startfile(st.session_state.output2)
                    st.warning("æ³¨æ„ï¼šæ–‡ä»¶å¤¹å·²æˆåŠŸæ‰“å¼€ï¼Œå¯èƒ½æœªç½®é¡¶æ˜¾ç¤ºï¼Œè¯·æ£€æŸ¥ä»»åŠ¡æ ï¼")
            except:
                st.warning('è¿™é‡Œæ˜¯ç¬¬äºŒæ¬¡çš„è§†é¢‘é¢„è§ˆçª—å£ï¼Œè¿è¡Œåè‡ªåŠ¨æ˜¾ç¤ºé¢„è§ˆç»“æœã€‚')
