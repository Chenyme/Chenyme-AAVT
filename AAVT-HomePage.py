import os
import toml
import shutil
import streamlit as st
from openai import OpenAI
from utils.utils import (convert_size, cache)


st.set_page_config(
    page_title="AAVT v0.5",
    page_icon="ğŸï¸",
    layout="wide",  # è®¾ç½®å¸ƒå±€æ ·å¼ä¸ºå®½å±•ç¤º
    initial_sidebar_state="expanded"  # è®¾ç½®åˆå§‹è¾¹æ çŠ¶æ€ä¸ºå±•å¼€
)


project_dir = os.path.dirname(os.path.abspath(__file__)).replace("\\", "/")
log_dir = project_dir + "/public/log.md"  # æ›´æ–°æ—¥å¿—
read_dir = project_dir + "/public/README.md"  # é¡¹ç›®æ–‡æ¡£
config_dir = project_dir + "/config/"  # é…ç½®æ–‡ä»¶
cache_dir = project_dir + "/pages/cache/"  # æœ¬åœ°ç¼“å­˜

with open(read_dir, 'r', encoding='utf-8') as file:
    markdown_content = file.read()

config = toml.load(config_dir + "config.toml")  # åŠ è½½é…ç½®
st.session_state.openai_key = config["GPT"]["openai_key"]
st.session_state.openai_base = config["GPT"]["openai_base"]

st.title("ğŸ–¥Chenyme-AAVT Version:0.5")
st.caption("POWERED BY @CHENYME")

tab1, tab2, tab3 = st.tabs(["ä¸»é¡µ", "è®¾ç½®", "å…³äº"])
with tab1:  # ä¸»ç•Œé¢åŠŸèƒ½
    messages = st.container(height=500)
    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "æˆ‘æ˜¯æœ¬é¡¹ç›®çš„AIå°åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„ä¹ˆ?"}]

    for msg in st.session_state.messages:
        messages.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input():
        client = OpenAI(api_key=st.session_state.openai_key)
        st.session_state.messages.append({"role": "user", "content": prompt})
        messages.chat_message("user").write(prompt)
        response = client.chat.completions.create(model="gpt-3.5-turbo", messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåŸºäºä¸‹é¢å†…å®¹çš„AIå°åŠ©æ‰‹ï¼Œè¯·åŸºäºä¸‹é¢çš„å†…å®¹å’Œè‡ªå·±çš„çŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ã€‚" + markdown_content},
                                                                                   {"role": "user", "content": prompt}])
        msg = response.choices[0].message.content
        st.session_state.messages.append({"role": "assistant", "content": msg})
        messages.chat_message("assistant").write(msg)

with tab2:
    openai_api_key = config["GPT"]["openai_key"]
    openai_api_base = config["GPT"]["openai_base"]
    kimi_api_key = config["KIMI"]["kimi_key"]
    whisper_version = config["WHISPER"]["whisper_version_default"]
    whisper_model = config["WHISPER"]["whisper_model_default"]

    # Whisperæ¨¡å‹
    st.write("#### Whisperè¯†åˆ«è®¾ç½®")
    st.write("é•¿è§†é¢‘æ¨èä½¿ç”¨Faster-whisperå’Œlargeæ¨¡å‹è·å¾—æœ€ä½³æ–­å¥ã€è¯†åˆ«ä½“éªŒã€‚")
    w_version_d = {'openai-whisper': 0, 'faster-whisper': 1}
    w_model_d = {'tiny': 0, 'base': 1, 'small': 2, 'medium': 3, 'large': 4}
    w_version = st.selectbox('é€‰æ‹©whisperç‰ˆæœ¬', ('openai-whisper', 'faster-whisper'),
                             index=w_version_d[whisper_version])
    w_model_option = st.selectbox('é€‰æ‹©è¯†åˆ«æ¨¡å‹', ('tiny', 'base', 'small', 'medium', 'large'),
                                  index=w_model_d[whisper_model])

    if w_version != whisper_version:
        config["WHISPER"]["whisper_version_default"] = w_version
        with open(config_dir + '/config.toml', 'w', encoding='utf-8') as file:
            toml.dump(config, file)

        st.success("é»˜è®¤ç‰ˆæœ¬å·²åˆ‡æ¢ä¸ºï¼š" + w_version)
    if w_model_option != whisper_model:
        config["WHISPER"]["whisper_model_default"] = w_model_option
        with open(config_dir + '/config.toml', 'w', encoding='utf-8') as file:
            toml.dump(config, file)
        st.success("é»˜è®¤æ¨¡å‹å·²åˆ‡æ¢ä¸ºï¼š" + w_model_option)
    st.write('------')

    # OPENAIè´¦æˆ·
    st.write("#### ç¿»è¯‘è®¾ç½®")
    st.write("##### KIMIè´¦æˆ·è®¾ç½®")
    new_kimi_key = st.text_input("KIMI-API-KEYï¼š")
    st.write("##### OPENAIè´¦æˆ·è®¾ç½®")
    proxy_on = st.toggle('å¯ç”¨ä»£ç†', help='å¦‚æœä½ èƒ½ç›´æ¥è®¿é—®openai.comï¼Œåˆ™æ— éœ€å¯ç”¨ã€‚')
    new_openai_key = st.text_input("OPENAI-API-KEYï¼š")
    new_openai_base = st.text_input("OPENAI-API-BASEï¼š")

    if st.button("ä¿å­˜"):
        if new_kimi_key != kimi_api_key and new_kimi_key != "":
            config["KIMI"]["kimi_key"] = new_kimi_key
            kimi_api_key = new_kimi_key
        if new_openai_base != openai_api_base and new_openai_base != "":
            config["GPT"]["openai_base"] = new_openai_base
            openai_api_base = new_openai_base
        if new_openai_key != openai_api_key and new_openai_key != "":
            config["GPT"]["openai_key"] = new_openai_key
            openai_api_key = new_openai_key
        with open(config_dir + "config.toml", 'w', encoding='utf-8') as file:
            toml.dump(config, file)
        st.success("å·²ä¿å­˜")
    st.write('------')

    # æœ¬åœ°ç¼“å­˜
    st.write("#### æœ¬åœ°ç¼“å­˜")
    st.write(f"æœ¬åœ°ç¼“å­˜å·²å ç”¨ï¼š{convert_size(cache(cache_dir))}")
    if st.button("æ¸…é™¤æœ¬åœ°ç¼“å­˜"):
        # è·å–æ–‡ä»¶å¤¹å†…æ‰€æœ‰æ–‡ä»¶çš„åˆ—è¡¨
        file_list = os.listdir(cache_dir)
        if not file_list:
            st.error("æ— æœ¬åœ°ç¼“å­˜æ–‡ä»¶ã€‚")
        else:
            # éå†åˆ—è¡¨ä¸­çš„æ–‡ä»¶ï¼Œå¹¶åˆ é™¤æ¯ä¸ªæ–‡ä»¶
            for file_name in file_list:
                file_path = os.path.join(cache_dir, file_name)
                print('å·²åˆ é™¤æ–‡ä»¶å¤¹:\n' + file_path)
                shutil.rmtree(file_path)
            st.success("æ‰€æœ‰ç¼“å­˜æ–‡ä»¶å·²æˆåŠŸåˆ é™¤ã€‚")

    st.session_state.openai_base = openai_api_base
    st.session_state.openai_key = openai_api_key
    st.session_state.kimi_key = kimi_api_key
    st.session_state.proxy_on = proxy_on
    st.session_state.w_model_option = w_model_option
    st.session_state.w_name = w_version

with tab3:
    with open(log_dir, 'r', encoding='utf-8') as file:
        markdown_log = file.read()
    st.write(markdown_log)
    st.caption('ç”±æœ¬åœ°log.mdè¯»å–åŠ è½½')
    st.write('')
    st.write('')
    st.write('')
    st.write('')
    st.write('')
    st.write('')
    st.write(markdown_content)
    st.caption('ç”±æœ¬åœ°README.mdè¯»å–åŠ è½½')