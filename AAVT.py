import os
import toml
import shutil
import streamlit as st
from openai import OpenAI
from utils.utils import (convert_size, cache)
import streamlit_antd_components as sac
from project.audio import audio
from project.video import video
from project.laboratory import laboratory

st.set_page_config(
    page_title="AAVT v0.7",
    page_icon="ğŸï¸",
    layout="wide",  # è®¾ç½®å¸ƒå±€æ ·å¼ä¸ºå®½å±•ç¤º
    initial_sidebar_state="expanded"  # è®¾ç½®åˆå§‹è¾¹æ çŠ¶æ€ä¸ºå±•å¼€
)

with st.sidebar.container():
    menu = sac.menu(
        items=[
            sac.MenuItem('ä¸»é¡µ', icon='house-fill'),
            sac.MenuItem('æˆ‘çš„é¡¹ç›®', icon='box-fill', children=[
                sac.MenuItem('éŸ³é¢‘', icon='mic'),
                sac.MenuItem('è§†é¢‘', icon='camera-reels'),
                sac.MenuItem('å®éªŒå®¤', icon='sliders')]),
        ],
        key='menu',
        open_index=[1]
    )
    sac.divider('æ²¡æœ‰æ›´å¤šå•¦~', align='center', color='gray')

with st.container():
    if menu == 'éŸ³é¢‘':
        audio()
    elif menu == 'è§†é¢‘':
        video()
    elif menu == 'å®éªŒå®¤':
        laboratory()

    else:
        # ä¸»é¡µé¢
        project_dir = os.path.dirname(os.path.abspath(__file__)).replace("\\", "/")
        log_dir = project_dir + "/public/log.md"  # æ›´æ–°æ—¥å¿—
        read_dir = project_dir + "/public/README.md"  # é¡¹ç›®æ–‡æ¡£
        model_dir = project_dir + "/models"  # æ¨¡å‹ç›®å½•
        config_dir = project_dir + "/config/"  # é…ç½®æ–‡ä»¶
        cache_dir = project_dir + "/project/cache/"  # æœ¬åœ°ç¼“å­˜

        with open(read_dir, 'r', encoding='utf-8') as file:
            markdown_content = file.read()

        st.title("ğŸ–¥Chenyme-AAVT V0.7")
        st.caption("POWERED BY @CHENYME")

        tab1, tab2, tab3 = st.tabs(["ä¸»é¡µ", "è®¾ç½®", "å…³äº"])
        with tab1:  # ä¸»ç•Œé¢åŠŸèƒ½
            messages = st.container(height=400)
            if "messages" not in st.session_state:
                st.session_state["messages"] = [
                    {"role": "assistant", "content": "æˆ‘æ˜¯æœ¬é¡¹ç›®çš„AIå°åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„ä¹ˆ?"}]

            for msg in st.session_state.messages:
                messages.chat_message(msg["role"]).write(msg["content"])

            if prompt := st.chat_input():
                client = OpenAI(api_key=st.session_state.openai_key)
                st.session_state.messages.append({"role": "user", "content": prompt})
                messages.chat_message("user").write(prompt)
                response = client.chat.completions.create(model="gpt-3.5-turbo", messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåŸºäºä¸‹é¢å†…å®¹çš„AIå°åŠ©æ‰‹ï¼Œè¯·åŸºäºä¸‹é¢çš„å†…å®¹å’Œè‡ªå·±çš„çŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ã€‚" + markdown_content},
                                                                                           {"role": "user", "content": prompt}])
                msg = response.choices[0].message.content
                st.session_state.messages.append({"role": "assistant", "content": msg})
                messages.chat_message("assistant").write(msg)

        with tab2:
            config = toml.load(config_dir + "config.toml")  # åŠ è½½é…ç½®
            openai_api_key = config["GPT"]["openai_key"]
            openai_api_base = config["GPT"]["openai_base"]
            kimi_api_key = config["KIMI"]["kimi_key"]
            deepseek_api_key = config["DEEPSEEK"]["deepseek_key"]
            chatglm_api_key = config["CHATGLM"]["chatglm_key"]
            openai_whisper_api = config["WHISPER"]["openai_whisper_api"]  # openai_whisperé…ç½®
            faster_whisper_model = config["WHISPER"]["faster_whisper_model_default"]  # faster_whisperé…ç½®
            faster_whisper_local = config["WHISPER"]["faster_whisper_model_local"]  # æœ¬åœ°æ¨¡å‹åŠ è½½
            faster_whisper_local_path = config["WHISPER"]["faster_whisper_model_local_path"]  # æœ¬åœ°æ¨¡å‹è·¯å¾„

            st.session_state.openai_key = openai_api_key  # ç¼“å­˜key
            st.session_state.openai_base = openai_api_base  # ç¼“å­˜base
            st.session_state.kimi_key = kimi_api_key  # ç¼“å­˜key
            st.session_state.deepseek_key = deepseek_api_key  # ç¼“å­˜key
            st.session_state.chatglm_key = chatglm_api_key  # ç¼“å­˜key

            options = {'faster-whisper': {'models': {'tiny': 0, 'tiny.en': 1, 'base': 2, 'base.en': 3, 'small': 4,
                                                     'small.en': 5, 'medium': 6, 'medium.en': 7, 'large-v1': 8,
                                                     'large-v2': 9, 'large-v3': 10, 'large': 11, 'distil-small.en': 12,
                                                     'distil-medium.en': 13, 'distil-large-v2': 14,
                                                     'distil-large-v3': 15}}}

            # Whisperæ¨¡å‹
            st.write("#### Whisperè¯†åˆ«è®¾ç½®")
            index = 1
            if openai_whisper_api:
                index = 0
            set_model = st.selectbox("é€‰æ‹©whisperè¯†åˆ«æ¨¡å¼", ("Openai-api æ¥å£è°ƒç”¨", "Faster-whisper æœ¬åœ°éƒ¨ç½²"),
                                     index=index)

            if set_model == "Faster-whisper æœ¬åœ°éƒ¨ç½²":
                w_local = st.checkbox('å¯ç”¨æœ¬åœ°æ¨¡å‹', faster_whisper_local)
                if w_local:
                    model_names = os.listdir(model_dir)
                    path = faster_whisper_local_path
                    try:
                        index_model = model_names.index(path.replace(model_dir + '/', ''))
                    except:
                        index_model = 0
                    w_local_option = st.selectbox('é€‰æ‹©æœ¬åœ°æ¨¡å‹', model_names, index=index_model)
                    w_local_model_path = model_dir + '/' + w_local_option
                    st.write("```æ¨èä½¿ç”¨ large æ¨¡å‹è·å¾—æœ€ä½³æ–­å¥ã€è¯†åˆ«ä½“éªŒï¼ï¼ï¼```")
                    st.write(
                        "```è‹¥å¼€å¯GPUè¯·æ³¨æ„ï¼šæœ€æ–°ç‰ˆæœ¬ä»…æ”¯æŒ CUDA 12ã€‚å¯¹äº CUDA 11ï¼Œå½“å‰çš„è§£å†³æ–¹æ³•æ˜¯é™çº§ ctranslate2==3.24.0ã€‚```")
                    st.write("```æ¨¡å‹ä¸‹è½½ï¼š```" + "[Huggingface.co / Systran](https://huggingface.co/Systran)")
                    config["WHISPER"]["faster_whisper_model_local"] = w_local
                    config["WHISPER"]["faster_whisper_model_local_path"] = w_local_model_path
                else:
                    w_model_option = st.selectbox('é€‰æ‹©è¯†åˆ«æ¨¡å‹', list(options['faster-whisper']['models'].keys()),
                                                  index=options['faster-whisper']['models'][faster_whisper_model])
                    st.write("```æ¨èä½¿ç”¨ large æ¨¡å‹è·å¾—æœ€ä½³æ–­å¥ã€è¯†åˆ«ä½“éªŒï¼ï¼ï¼```")
                    st.write(
                        "```è‹¥å¼€å¯GPUè¯·æ³¨æ„ï¼šæœ€æ–°ç‰ˆæœ¬ä»…æ”¯æŒ CUDA 12ã€‚å¯¹äº CUDA 11ï¼Œå½“å‰çš„è§£å†³æ–¹æ³•æ˜¯é™çº§ ctranslate2==3.24.0ã€‚```")
                    config["WHISPER"]["faster_whisper_model_local"] = w_local
                    config["WHISPER"]["faster_whisper_model_default"] = w_model_option
                config["WHISPER"]["openai_whisper_api"] = False
            else:
                config["WHISPER"]["openai_whisper_api"] = True
                st.write("è¯·æ³¨æ„APIè°ƒç”¨å¿…é¡»åœ¨ä¸‹æ–¹ç¿»è¯‘è®¾ç½®ä¸­é…ç½®å¥½OPENAIç›¸å…³è®¾ç½®ï¼Œå¦åˆ™æ— æ³•ä½¿ç”¨ï¼ï¼ï¼")

            with open(config_dir + '/config.toml', 'w', encoding='utf-8') as file:
                toml.dump(config, file)

            st.write('---')
            st.write("#### ç¿»è¯‘è®¾ç½®")


            @st.experimental_dialog("ç¿»è¯‘è®¾ç½®")
            def select(item):
                if item == 'KIMI':
                    new_kimi_key = st.text_input("KIMI-API-KEYï¼š", st.session_state.kimi_key)
                    st.write('''```Kimi æ˜¯ç”±æœˆä¹‹æš—é¢ï¼ˆMoonshot AIï¼‰å›¢é˜Ÿçš„è¶…é•¿è®°å¿† AI åŠ©æ‰‹ã€‚```''')
                    st.write('''```å®˜ç½‘ï¼šhttps://www.moonshot.cn/```''')
                    st.session_state.kimi_key = new_kimi_key
                if item == 'OPENAI':
                    new_openai_key = st.text_input("OPENAI-API-KEYï¼š", st.session_state.openai_key)
                    new_openai_base = st.text_input("OPENAI-API-BASEï¼š", st.session_state.openai_base)
                    st.write('''```å®˜ç½‘ï¼šhttps://openai.com/```''')
                    st.session_state.openai_key = new_openai_key
                    st.session_state.openai_base = new_openai_base
                if item == 'DEEPSEEK':
                    new_deepseek_key = st.text_input("DEEPSEEK-API-KEYï¼š", st.session_state.deepseek_key)
                    st.write('''```DeepSeek å‘å¸ƒå…¨çƒæœ€å¼ºå¼€æº MoE æ¨¡å‹ DeepSeek-V2ï¼Œå¯¹è¯å®˜ç½‘/API å·²å…¨é¢å‡çº§ï¼Œæ”¯æŒ 32K ä¸Šä¸‹æ–‡```''')
                    st.write('''```å®˜ç½‘ï¼šhttps://www.deepseek.com/```''')
                    st.session_state.deepseek_key = new_deepseek_key
                if item == 'CHATGLM':
                    new_chatglm_key = st.text_input("CHATGLM-API-KEYï¼š", st.session_state.chatglm_key)
                    st.write('''```åŸºäºé¢†å…ˆçš„åƒäº¿çº§å¤šè¯­è¨€ã€å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ‰“é€ é«˜æ•ˆç‡ã€é€šç”¨åŒ–çš„â€œæ¨¡å‹å³æœåŠ¡â€AIå¼€å‘æ–°èŒƒå¼```''')
                    st.write('''```å®˜ç½‘ï¼šhttps://open.bigmodel.cn/```''')
                    st.session_state.chatglm_key = new_chatglm_key

                kimi_key = st.session_state.kimi_key
                openai_key = st.session_state.openai_key
                openai_base = st.session_state.openai_base
                deepseek_key = st.session_state.deepseek_key
                chatglm_key = st.session_state.chatglm_key

                st.write("")
                if sac.buttons([sac.ButtonsItem(label='ä¿å­˜', icon='floppy2-fill', color='dark')], index=None, align='center', variant='filled', use_container_width=True):
                    config["KIMI"]["kimi_key"] = kimi_key
                    config["GPT"]["openai_base"] = openai_base
                    config["GPT"]["openai_key"] = openai_key
                    config["DEEPSEEK"]["deepseek_key"] = deepseek_key
                    config["CHATGLM"]["chatglm_key"] = chatglm_key
                    with open(config_dir + "/config.toml", 'w', encoding='utf-8') as file:
                        toml.dump(config, file)
                    st.success("å·²ä¿å­˜")


            if "ç¿»è¯‘è®¾ç½®" not in st.session_state:
                button = sac.buttons([
                    sac.ButtonsItem(label='é€‰æ‹©ä½ è¦é…ç½®çš„æ¨¡å‹'),
                    sac.ButtonsItem(label='OpenAI-ChatGPT', icon='chat-quote-fill', color='red'),
                    sac.ButtonsItem(label='æœˆä¹‹æš—é¢-Kimi', icon='chat-quote-fill', color='indigo'),
                    sac.ButtonsItem(label='æ™ºè°±AI-ChatGLM', icon='chat-quote-fill', color='blue'),
                    sac.ButtonsItem(label='æ·±åº¦æ±‚ç´¢-DeepSeek', icon='chat-quote-fill', color='green'),
                    sac.ButtonsItem(label='ç°å·²æ”¯æŒæœ¬åœ°éƒ¨ç½²è°ƒç”¨', icon='robot'),
                    sac.ButtonsItem(label='æ›´å¤šæ”¯æŒ?', icon='arrow-up-right-square-fill', href='https://github.com/Chenyme/Chenyme-AAVT/issues'),
                ], index=None, align='center', variant='text', direction='vertical', use_container_width=True, return_index=True)

                if button == 1:
                    select("OPENAI")
                if button == 2:
                    select("KIMI")
                if button == 3:
                    select("CHATGLM")
                if button == 4:
                    select("DEEPSEEK")
                if button == 5:
                    a = "???"

            st.write('---')

            # æœ¬åœ°ç¼“å­˜
            st.write("#### æœ¬åœ°ç¼“å­˜")
            col1, col2, col3 = st.columns([0.48, 0.1, 0.42])
            col2.metric(label="æœ¬åœ°ç¼“å­˜", value=f"{convert_size(cache(cache_dir))}")
            if sac.buttons([sac.ButtonsItem(label='ç‚¹æˆ‘æ¸…ç†æœ¬åœ°æ‰€æœ‰ç¿»è¯‘é¡¹ç›®', icon='x-square')], index=None, align='center', color='dark', variant='dashed', use_container_width=True):
                if not os.listdir(cache_dir):
                    st.error("æ— æœ¬åœ°ç¼“å­˜æ–‡ä»¶ã€‚")
                else:
                    for root, dirs, files in os.walk(cache_dir):
                        for file in files:
                            os.remove(os.path.join(root, file))
                        for adir in dirs:
                            shutil.rmtree(os.path.join(root, adir))
                    st.success("æ‰€æœ‰ç¼“å­˜æ–‡ä»¶å·²æˆåŠŸåˆ é™¤ã€‚")

        with tab3:
            with open(log_dir, 'r', encoding='utf-8') as file:
                markdown_log = file.read()
            st.write(markdown_log)
            st.caption('ç”±æœ¬åœ°log.mdè¯»å–åŠ è½½')
            st.write('')
            st.write('')
            st.write('')
            st.write('')
            st.write('')
            st.write('')
            st.write(markdown_content)
            st.caption('ç”±æœ¬åœ°README.mdè¯»å–åŠ è½½')


